{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Mid-Term Review - October 2024 - SnowC2\n",
    "\n",
    "With physics + Arctic snow code modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Env: sc2_v0\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import proplot as pplt # New plot library (https://proplot.readthedocs.io/en/latest/)\n",
    "pplt.rc['savefig.dpi'] = 300 # 1200 is too big! #https://proplot.readthedocs.io/en/latest/basics.html#Creating-figures\n",
    "from scipy import stats\n",
    "import xesmf as xe # For regridding (https://xesmf.readthedocs.io/en/latest/)\n",
    "import calendar\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://www.w3schools.com/python/python_classes.asp\n",
    "\n",
    "class Site:\n",
    "  def __init__(self, name, long_name, location, lat, lon, elevation, period, start, stop, period_used, run):\n",
    "    self.name = name\n",
    "    self.long_name = long_name\n",
    "    self.location = location\n",
    "    self.lat = lat\n",
    "    self.lon = lon\n",
    "    self.elevation = elevation\n",
    "    self.period = period\n",
    "    self.start = start\n",
    "    self.stop = stop\n",
    "    self.period_used = period_used\n",
    "    self.run = run\n",
    "\n",
    "exps = [\n",
    "    # 'Ref_30min_ext',\n",
    "    'DEF',\n",
    "    # 'BUG_CORRECT',\n",
    "    # 'BUG_CORRECT_TSNBT_OP1',\n",
    "    # 'BUG_CORRECT_TSNBT_OP1_EZERO',\n",
    "    # 'PHYS_ALL_SUBLI',\n",
    "    # 'PHYS_ALL_SUBLI_COMPAC',\n",
    "    'PHYS_ALL_SUBLI_COMPAC_calonne',\n",
    "    'PHYS_ALL_SUBLI_CORRECT_COMPAC_calonne',\n",
    "\n",
    "]\n",
    "\n",
    "# SnowMIP\n",
    "cdp = Site('cdp', 'Col de Porte, France', '45.30°N, 5.77°E', 45.30, 5.77, '1325 m', \n",
    "           '1 October 1994 to 30 September 2014', '1994-10-01', '2014-09-30', slice('1994-10-01', '2014-09-30'), exps)\n",
    "\n",
    "rme = Site('rme', 'Reynolds Mountain East, Idaho, USA', '43.19°N, 116.78°W', 43.19, -116.78, '2060 m', \n",
    "           '1 October 1988 to 30 September 2008', '1988-10-01', '2008-09-30', slice('1988-10-01', '2008-09-30'), exps)\n",
    "\n",
    "snb = Site('snb', 'Senator Beck, Colorado, US', '37.91°N, 107.73°W', 37.91, -107.73, '3714 m', \n",
    "           '1 October 2005 to 30 September 2015', '2005-10-01', '2015-09-30', slice('2005-10-01', '2015-09-30'), exps)\n",
    "\n",
    "swa = Site('swa', 'Swamp Angel, Colorado, USA', '37.91°N, 107.71°W', 37.91, -107.71, '3371 m', \n",
    "           '1 October 2005 to 30 September 2015', '2005-10-01', '2015-09-30', slice('2005-10-01', '2015-09-30'), exps)\n",
    "\n",
    "sap = Site('sap', 'Sapporo, Japan', '43.08°N, 141.34°E', 43.08, 141.34, '15 m', \n",
    "           '1 October 2005 to 30 September 2015', '2005-10-01', '2015-09-30', slice('2005-10-01', '2015-09-30'), exps)\n",
    "\n",
    "sod = Site('sod', 'Sodankylä, Finland', '67.37°N, 26.63°E', 67.37, 26.63, '179 m', \n",
    "           '1 October 2007 to 30 September 2014', '2007-10-01', '2014-09-30', slice('2007-10-01', '2014-09-30'), exps)\n",
    "\n",
    "wfj = Site('wfj', 'Weissfluhjoch, Switzerland', '46.83°N, 9.81°E', 46.83, 9.81, '2540 m', \n",
    "           '1 September 1996 to 31 August 2016', '1996-10-01', '2016-08-31', slice('1996-10-01', '2016-08-31'), exps)\n",
    "\n",
    "# Arctic \n",
    "byl = Site('byl', 'Bylot Island, Canadian high Arctic', '73.15°N, 80.00°W', 73.15, -80.00, '25 m', \n",
    "           '11 July 2013 to 25 June 2019', '2013-07-11', '2019-06-25', slice('2014-07-11', '2019-06-25'), \n",
    "           [\n",
    "               # 'peat_30min_ext', \n",
    "               # 'peat_DEF',\n",
    "               # 'peat_BUG_CORRECT',\n",
    "               # 'peat_BUG_CORRECT_TSNBT_OP1',\n",
    "               # 'peat_BUG_CORRECT_TSNBT_OP1_EZERO',\n",
    "               # 'peat_PHYS_ALL_SUBLI',\n",
    "               # 'peat_PHYS_ALL_SUBLI_COMPAC',\n",
    "               'peat_PHYS_ALL_SUBLI_COMPAC_calonne',\n",
    "               'peat_PHYS_ALL_SUBLI_CORRECT_COMPAC_calonne',\n",
    "           ])\n",
    "\n",
    "umt = Site('umt', 'Umiujaq TUNDRA, northeastern Canada', '56.55877°N, 76.48234°W', 56.55877, -76.48234, '132 m', \n",
    "           '28 Sept 2012 to 15 October 2021', '2012-09-28', '2021-10-15', slice('2016-09-01', '2021-08-31'), \n",
    "           [\n",
    "               # 'Ref', \n",
    "               # 'DEF',\n",
    "               # 'BUG_CORRECT',\n",
    "               # 'BUG_CORRECT_TSNBT_OP1',\n",
    "               # 'BUG_CORRECT_TSNBT_OP1_EZERO',\n",
    "               # 'PHYS_ALL_SUBLI',\n",
    "               # 'PHYS_ALL_SUBLI_COMPAC',\n",
    "               'PHYS_ALL_SUBLI_COMPAC_calonne',\n",
    "               'PHYS_ALL_SUBLI_CORRECT_COMPAC_calonne',\n",
    "           ])\n",
    "\n",
    "# umf = Site('umf', 'Umiujaq FOREST, northeastern Canada', '56.55308°N, 76.47258°W', 56.55308, -76.47258, '82 m', \n",
    "#            '26 Nov 2015 to 19 October 2021', '2015-11-26', '2021-10-19', slice('2018-09-01', '2021-08-31'), \n",
    "#            ['Ref', 'EZERO'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m paths_SnowMIP \u001b[38;5;241m=\u001b[39m [path_SnowMIP\u001b[38;5;241m+\u001b[39msite\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mexp \u001b[38;5;28;01mfor\u001b[39;00m site \u001b[38;5;129;01min\u001b[39;00m SnowMIP_sites]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Change the syntax as the ref run is not necessarily having the same name for all sites\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m paths_SnowArctic \u001b[38;5;241m=\u001b[39m [path_SnowArctic\u001b[38;5;241m+\u001b[39msite\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39msite\u001b[38;5;241m.\u001b[39mrun[i] \u001b[38;5;28;01mfor\u001b[39;00m site \u001b[38;5;129;01min\u001b[39;00m SnowArctic_sites]\n\u001b[1;32m     14\u001b[0m paths \u001b[38;5;241m=\u001b[39m paths_SnowMIP \u001b[38;5;241m+\u001b[39m paths_SnowArctic\n\u001b[1;32m     15\u001b[0m ds_d_SnowMIP_list\u001b[38;5;241m.\u001b[39mappend([xr\u001b[38;5;241m.\u001b[39mopen_mfdataset(path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/*_daily.nc\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mload() \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m paths])\n",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     11\u001b[0m paths_SnowMIP \u001b[38;5;241m=\u001b[39m [path_SnowMIP\u001b[38;5;241m+\u001b[39msite\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mexp \u001b[38;5;28;01mfor\u001b[39;00m site \u001b[38;5;129;01min\u001b[39;00m SnowMIP_sites]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Change the syntax as the ref run is not necessarily having the same name for all sites\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m paths_SnowArctic \u001b[38;5;241m=\u001b[39m [path_SnowArctic\u001b[38;5;241m+\u001b[39msite\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[43msite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m site \u001b[38;5;129;01min\u001b[39;00m SnowArctic_sites]\n\u001b[1;32m     14\u001b[0m paths \u001b[38;5;241m=\u001b[39m paths_SnowMIP \u001b[38;5;241m+\u001b[39m paths_SnowArctic\n\u001b[1;32m     15\u001b[0m ds_d_SnowMIP_list\u001b[38;5;241m.\u001b[39mappend([xr\u001b[38;5;241m.\u001b[39mopen_mfdataset(path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/*_daily.nc\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mload() \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m paths])\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "SnowMIP_sites = [cdp, rme, snb, swa, sap, sod, wfj]\n",
    "# SnowMIP_sites = [cdp, rme, snb, sap, sod, wfj]\n",
    "SnowArctic_sites = [byl, umt]\n",
    "\n",
    "path_SnowMIP = '/home/lalandmi/eccc/classic-develop/outputFiles/SnowMIP/'\n",
    "path_SnowArctic = '/home/lalandmi/eccc/classic-develop/outputFiles/SnowArctic/'\n",
    "path_Paul = '/home/lalandmi/Dropbox/data/SnowMIP/Paul/CLASS_Results'\n",
    "\n",
    "ds_d_SnowMIP_list = []\n",
    "for i, exp in enumerate(exps):\n",
    "    paths_SnowMIP = [path_SnowMIP+site.name+'/'+'run_'+exp for site in SnowMIP_sites]\n",
    "    # Change the syntax as the ref run is not necessarily having the same name for all sites\n",
    "    paths_SnowArctic = [path_SnowArctic+site.name+'/'+'run_'+site.run[i] for site in SnowArctic_sites]\n",
    "    paths = paths_SnowMIP + paths_SnowArctic\n",
    "    ds_d_SnowMIP_list.append([xr.open_mfdataset(path+'/*_daily.nc').squeeze().load() for path in paths])\n",
    "\n",
    "\n",
    "# ds_d_Paul_list = []\n",
    "# for site in SnowMIP_sites:\n",
    "#     df_Paul = pd.read_csv(path_Paul+'/CLASS_sv_REF_'+site.name+'_'+site.start[:4]+'_'+site.stop[:4]+'.txt', delim_whitespace=True)\n",
    "#     df_Paul.index = pd.to_datetime(df_Paul[['year', 'month', 'day', 'hour']]).values\n",
    "#     df_Paul= df_Paul.drop(columns=['year', 'month', 'day', 'hour'])\n",
    "#     df_Paul.albsn = df_Paul.albsn.replace({0 : np.nan})\n",
    "#     df_Paul.albs = df_Paul.albs.replace({0 : np.nan})\n",
    "#     df_Paul.tsn = df_Paul.tsn.replace({-999 : np.nan})\n",
    "#     df_Paul.tsns = df_Paul.tsns.replace({-999 : np.nan})\n",
    "#     ds_Paul_h = df_Paul.to_xarray()\n",
    "#     ds_Paul_h = ds_Paul_h.rename({'index': 'time'})\n",
    "#     ds_Paul_d = ds_Paul_h.resample(time='D').mean().load()\n",
    "#     ds_Paul_d = ds_Paul_d.assign_coords(layer=[0.05 , 0.225, 2.225]) # center of Paul's soil layers (DELZ = [0.1, 0.25, 3.75])\n",
    "    \n",
    "\n",
    "#     # Combine the Soil temperature in one variable\n",
    "#     ds_Paul_d = ds_Paul_d.assign(\n",
    "#         tsl=(('layer', 'time'), [\n",
    "#             list(ds_Paul_d['tsl:1'].values),\n",
    "#             list(ds_Paul_d['tsl:2'].values),\n",
    "#             list(ds_Paul_d['tsl:3'].values),\n",
    "#         ])\n",
    "#     )\n",
    "        \n",
    "#     ds_d_Paul_list.append(ds_Paul_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set soil levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/lalandmi/eccc/classic-develop/inputFiles/SnowMIP/cdp\"\n",
    "rsfile = xr.open_dataset(path+'/rsfile_spinup-final_Ref.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def assign_center_depth(ds, rsfile):\n",
    "    layer_c = []\n",
    "    for i in range(len(rsfile.DELZ)):\n",
    "        if i == 0:\n",
    "            layer_c.append(rsfile.DELZ.cumsum().values[i]/2)\n",
    "        else:\n",
    "            layer_c.append(rsfile.DELZ.cumsum().values[i-1] + rsfile.DELZ.values[i]/2)\n",
    "    with xr.set_options(keep_attrs=True):\n",
    "        ds = ds.assign_coords(layer=ds.layer*0+layer_c)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, exp in enumerate(exps):\n",
    "    for j in range(len(SnowMIP_sites+SnowArctic_sites)):\n",
    "        ds_d_SnowMIP_list[i][j] = assign_center_depth(ds_d_SnowMIP_list[i][j], rsfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_menard2019 = '/home/lalandmi/Dropbox/data/ESM-SnowMIP_all'\n",
    "\n",
    "ds_d_Obs_list = []\n",
    "for site in SnowMIP_sites:\n",
    "    ds_h_eval_menard2019 = xr.open_dataset(path_menard2019+'/obs_insitu_'+site.name+'_'+site.start[:4]+'_'+site.stop[:4]+'.nc')\n",
    "    ds_d_eval_menard2019 = ds_h_eval_menard2019.resample(time='D').mean().load()\n",
    "    ds_d_Obs_list.append(ds_d_eval_menard2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_obs_byl = '/home/lalandmi/Dropbox/data/ESM-SnowMIP_all/Bylot'\n",
    "path_obs_umt = '/home/lalandmi/Dropbox/data/ESM-SnowMIP_all/Umiujaq/Domine-etal_2024/datasets'\n",
    "# path_obs_umf = '/home/lalandmi/Dropbox/data/ESM-SnowMIP_all/Umiujaq/Domine-etal_2024/datasets'\n",
    "\n",
    "# path_obs_list = [path_obs_byl, path_obs_umt, path_obs_umf]\n",
    "path_obs_list = [path_obs_byl, path_obs_umt]\n",
    "for site, path in zip(SnowArctic_sites, path_obs_list):\n",
    "    ds_h_obs = xr.open_dataset(path+'/obs_insitu_'+site.name+'_'+site.start[:4]+'_'+site.stop[:4]+'.nc').load()\n",
    "    if site.name == 'byl':\n",
    "        ds_h_obs['albs'] = ds_h_obs.albs.where(ds_h_obs.flag_albs_ERA5 == 0).where(ds_h_obs.albs < 1) # to avoid > 1 albedo values\n",
    "    if site.name == 'umt':\n",
    "        ds_h_obs = ds_h_obs.mean(dim='veg') # average over lichen and lowshrub area (tsl)\n",
    "    # Remove albs for Arctic sites (wrong values)\n",
    "    if site.name in ['byl', 'umt']:\n",
    "        ds_h_obs = ds_h_obs.drop_vars('albs')\n",
    "    ds_d_obs = ds_h_obs.resample(time='D').mean().load()\n",
    "    ds_d_Obs_list.append(ds_d_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Arctic and SnowMIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_d_Obs_list = ds_d_Obs_list + ds_d_Obs_Arctic_list\n",
    "# ds_d_SnowMIP_list = ds_d_SnowMIP_list + ds_d_SnowArctic_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = pplt.subplots(nrows=len(SnowMIP_sites+SnowArctic_sites), refaspect=12, refwidth=8, space=0)\n",
    "\n",
    "color_obs = 'gray8'\n",
    "\n",
    "for i, site in enumerate(SnowMIP_sites+SnowArctic_sites):\n",
    "    # Model \n",
    "    h_exps = []\n",
    "    for j, exp in enumerate(exps): \n",
    "        h = axs[i].plot(ds_d_SnowMIP_list[j][i].snd.sel(time=slice(site.start, site.stop)), label=exp, lw=1)\n",
    "        h_exps.append(h)\n",
    "\n",
    "    # if site.name in [site_SnowMIP.name for site_SnowMIP in SnowMIP_sites]:\n",
    "    #     h_paul = axs[i].plot(ds_d_Paul_list[i].snd.sel(time=slice(site.start, site.stop)), label='CLASS', color='red9', lw=1)\n",
    "    \n",
    "    # Obs\n",
    "    shadedata = np.concatenate((\n",
    "        np.expand_dims(ds_d_Obs_list[i].snd_auto.sel(time=slice(site.start, site.stop)).values+0.1, axis=0),\n",
    "        np.expand_dims(ds_d_Obs_list[i].snd_auto.sel(time=slice(site.start, site.stop)).values-0.1, axis=0),), axis=0)\n",
    "    h_obs_auto = axs[i].plot(ds_d_Obs_list[i].snd_auto.sel(time=slice(site.start, site.stop)), shadedata=shadedata, color=color_obs, \n",
    "                zorder=0, lw=0.8, label='Obs (auto)')\n",
    "    \n",
    "    if 'snd_man' in list(ds_d_Obs_list[i].keys()):\n",
    "        h_obs_man = axs[i].plot(ds_d_Obs_list[i].snd_man.sel(time=slice(site.start, site.stop)), marker='.', color=color_obs, \n",
    "                    zorder=0, lw=0.8, label='Obs (man)')\n",
    "    \n",
    "    axs[i].format(ylabel='Snow depth (m)', ultitle=site.long_name+' ('+site.elevation+')')\n",
    "    axs[i].vlines(ds_d_SnowMIP_list[j][i].sel(time=site.period_used).time[0], axs[i].get_ylim()[0], axs[i].get_ylim()[1], \n",
    "                  color='k', lw=0.8)\n",
    "    axs[i].vlines(ds_d_SnowMIP_list[j][i].sel(time=site.period_used).time[-1], axs[i].get_ylim()[0], axs[i].get_ylim()[1], \n",
    "                  color='k', lw=0.8)\n",
    "    \n",
    "\n",
    "\n",
    "# axs[4].legend(ncols=5, loc='ll')\n",
    "# fig.legend(h_exps+h_paul+h_obs_auto+h_obs_man, ncols=2, loc='t')\n",
    "fig.legend(h_exps+h_obs_auto+h_obs_man, ncols=2, loc='t')\n",
    "\n",
    "fig.format(abc='(a)', abcloc='ur')\n",
    "\n",
    "# fig.suptitle('Col de Porte, France, 1325 m')\n",
    "# fig.save('img/tn1_sd.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annual cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[site.name for site in SnowMIP_sites+SnowArctic_sites]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "color_obs = 'gray8'\n",
    "\n",
    "# fig, axs = pplt.subplots(ncols=5, nrows=len(SnowMIP_sites+SnowArctic_sites), refwidth=1.5, sharey=0)\n",
    "fig, axs = pplt.subplots(ncols=5, nrows=len(SnowMIP_sites+SnowArctic_sites), refwidth=1.5, sharey=0, hspace=1, refaspect=1.4)\n",
    "\n",
    "# for i, site in enumerate([cdp]):\n",
    "for i, site in enumerate(SnowMIP_sites+SnowArctic_sites):\n",
    "\n",
    "    doy = 140\n",
    "    period = site.period_used\n",
    "\n",
    "    # Snow depth\n",
    "    ax = axs[i*5+0]\n",
    "    mask_obs = ~ds_d_Obs_list[i].snd_auto.sel(time=period).isnull()\n",
    "    \n",
    "    shadedata = ds_d_SnowMIP_list[0][i].snd.sel(time=period).where(mask_obs).groupby('time.dayofyear').quantile([0.1, 0.9])\\\n",
    "                .sel(dayofyear=slice(1,365)).roll(dayofyear=doy).transpose('quantile', 'dayofyear')\n",
    "    h1 = ax.plot(ds_d_SnowMIP_list[0][i].snd.sel(time=period).where(mask_obs).groupby('time.dayofyear').mean()\\\n",
    "                 .sel(dayofyear=slice(1,365)).roll(dayofyear=doy), shadedata=shadedata, label=exps[0], zorder=1, lw=1)\n",
    "    h_exps = []\n",
    "    for j, exp in enumerate(exps[1:]):\n",
    "        h = ax.plot(ds_d_SnowMIP_list[j+1][i].snd.sel(time=period).where(mask_obs).groupby('time.dayofyear').mean()\\\n",
    "                 .sel(dayofyear=slice(1,365)).roll(dayofyear=doy), label=exp, lw=1)\n",
    "        h_exps.append(h)\n",
    "\n",
    "    # if site.name in [site_SnowMIP.name for site_SnowMIP in SnowMIP_sites]:\n",
    "    #     h_paul = ax.plot(ds_d_Paul_list[i].snd.sel(time=period).where(mask_obs).groupby('time.dayofyear').mean()\\\n",
    "    #                  .sel(dayofyear=slice(1,365)).roll(dayofyear=doy), label='CLASS', color='red9', zorder=9, lw=1)\n",
    "    \n",
    "    obs = ds_d_Obs_list[i].snd_auto.sel(time=period).groupby('time.dayofyear').mean().sel(dayofyear=slice(1,365)).roll(dayofyear=doy)\n",
    "    shadedata = np.concatenate((np.expand_dims(obs.values+0.1, axis=0), np.expand_dims(obs.values-0.1, axis=0),), axis=0)\n",
    "    h_obs = ax.plot(obs, shadedata=shadedata, label='Obs', color=color_obs, lw=0.8, zorder=10)\n",
    "    ax.format(ylabel='', ylim=(-0.2,3),\n",
    "              ultitle=str(ds_d_Obs_list[i].sel(time=period).snd_auto.dropna(dim='time').time[0].values)[:10]+' to\\n'+ \\\n",
    "              str(ds_d_Obs_list[i].sel(time=period).snd_auto.dropna(dim='time').time[-1].values)[:10])    \n",
    "    # ax.legend(h1+h_exps+h_paul+h_obs, loc='ul', ncols=1)\n",
    "    \n",
    "    # Snow Water Equivalent\n",
    "    ax = axs[i*5+1]\n",
    "\n",
    "    if 'snw_auto' in list(ds_d_Obs_list[i].keys()):\n",
    "        mask_obs = ~ds_d_Obs_list[i].snw_auto.sel(time=period).isnull()\n",
    "        \n",
    "        shadedata = ds_d_SnowMIP_list[0][i].snw.sel(time=period).where(mask_obs).groupby('time.dayofyear').quantile([0.1, 0.9])\\\n",
    "                    .sel(dayofyear=slice(1,365)).roll(dayofyear=doy).transpose('quantile', 'dayofyear')\n",
    "        h1 = ax.plot(ds_d_SnowMIP_list[0][i].snw.sel(time=period).where(mask_obs).groupby('time.dayofyear').mean()\\\n",
    "                     .sel(dayofyear=slice(1,365)).roll(dayofyear=doy), shadedata=shadedata, label=exps[0], zorder=1, lw=1)\n",
    "        h_exps = []\n",
    "        for j, exp in enumerate(exps[1:]):\n",
    "            h = ax.plot(ds_d_SnowMIP_list[j+1][i].snw.sel(time=period).where(mask_obs).groupby('time.dayofyear').mean()\\\n",
    "                     .sel(dayofyear=slice(1,365)).roll(dayofyear=doy), label=exp, lw=1)\n",
    "            h_exps.append(h)\n",
    "\n",
    "        # if site.name in [site_SnowMIP.name for site_SnowMIP in SnowMIP_sites]:\n",
    "        #     h_paul = ax.plot(ds_d_Paul_list[i].snw.sel(time=period).where(mask_obs).groupby('time.dayofyear').mean()\\\n",
    "        #                  .sel(dayofyear=slice(1,365)).roll(dayofyear=doy), label='CLASS', color='red9', zorder=9, lw=1)\n",
    "        \n",
    "        obs = ds_d_Obs_list[i].snw_auto.sel(time=period).groupby('time.dayofyear').mean().sel(dayofyear=slice(1,365)).roll(dayofyear=doy)\n",
    "        shadedata = np.concatenate((np.expand_dims(obs.values+25, axis=0), np.expand_dims(obs.values-25, axis=0),), axis=0)\n",
    "        h_obs = ax.plot(obs, shadedata=shadedata, label='Obs', color=color_obs, lw=0.8, zorder=10)\n",
    "        ax.format(ylabel='', ylim=(-40,1200),\n",
    "                  ultitle=str(ds_d_Obs_list[i].sel(time=period).snw_auto.dropna(dim='time').time[0].values)[:10]+' to\\n'+ \\\n",
    "                  str(ds_d_Obs_list[i].sel(time=period).snw_auto.dropna(dim='time').time[-1].values)[:10]) \n",
    "\n",
    "    else:\n",
    "        shadedata = ds_d_SnowMIP_list[0][i].snw.sel(time=period).groupby('time.dayofyear').quantile([0.1, 0.9])\\\n",
    "                    .sel(dayofyear=slice(1,365)).roll(dayofyear=doy).transpose('quantile', 'dayofyear')\n",
    "        h1 = ax.plot(ds_d_SnowMIP_list[0][i].snw.sel(time=period).groupby('time.dayofyear').mean()\\\n",
    "                     .sel(dayofyear=slice(1,365)).roll(dayofyear=doy), shadedata=shadedata, label=exps[0], zorder=1, lw=1)\n",
    "        h_exps = []\n",
    "        for j, exp in enumerate(exps[1:]):\n",
    "            h = ax.plot(ds_d_SnowMIP_list[j+1][i].snw.sel(time=period).groupby('time.dayofyear').mean()\\\n",
    "                     .sel(dayofyear=slice(1,365)).roll(dayofyear=doy), label=exp, lw=1)\n",
    "            h_exps.append(h)\n",
    "\n",
    "        # if site.name in [site_SnowMIP.name for site_SnowMIP in SnowMIP_sites]:\n",
    "        #     h_paul = ax.plot(ds_d_Paul_list[i].snw.sel(time=period).groupby('time.dayofyear').mean()\\\n",
    "        #                  .sel(dayofyear=slice(1,365)).roll(dayofyear=doy), label='CLASS', color='red9', zorder=9, lw=1)\n",
    "        \n",
    "        ax.format(ylabel='', ylim=(-40,1200), ultitle=period.start+' to\\n'+ period.stop)\n",
    "\n",
    "\n",
    "    # Albedo (need to add a condition albsn > 0.4 because a few values are 0 in the model -> bug? (e.g., at Saporo)\n",
    "    # + low values are observed in the begining of the season (probably due to not full SCF coveraged)\n",
    "    ax = axs[i*5+2]\n",
    "    lim_alb = 0.4\n",
    "    lim_alb_sup = 0.9\n",
    "\n",
    "    if 'albs' in list(ds_d_Obs_list[i].keys()):\n",
    "        mask_obs = ~ds_d_Obs_list[i].albs.where(ds_d_Obs_list[i].albs > lim_alb).where(ds_d_Obs_list[i].albs < lim_alb_sup)\\\n",
    "                    .where(ds_d_Obs_list[i].snd_auto > 0.1).sel(time=period).isnull()\n",
    "        \n",
    "        shadedata = ds_d_SnowMIP_list[0][i].albsn.sel(time=period).where(ds_d_SnowMIP_list[0][i].albsn > lim_alb) \\\n",
    "                    .where(ds_d_SnowMIP_list[0][i].albsn < lim_alb_sup)\\\n",
    "                    .where(ds_d_SnowMIP_list[0][i].snd > 0.1).where(mask_obs).groupby('time.dayofyear').quantile([0.1, 0.9])\\\n",
    "                    .sel(dayofyear=slice(1,365)).roll(dayofyear=doy).transpose('quantile', 'dayofyear')\n",
    "        h1 = ax.plot(ds_d_SnowMIP_list[0][i].albsn.sel(time=period).where(ds_d_SnowMIP_list[0][i].albsn > lim_alb) \\\n",
    "                     .where(ds_d_SnowMIP_list[0][i].albsn < lim_alb_sup)\\\n",
    "                     .where(ds_d_SnowMIP_list[0][i].snd > 0.1).where(mask_obs).groupby('time.dayofyear').mean()\\\n",
    "                     .sel(dayofyear=slice(1,365)).roll(dayofyear=doy), shadedata=shadedata, label=exps[0], zorder=1, lw=1)\n",
    "        h_exps = []\n",
    "        for j, exp in enumerate(exps[1:]):\n",
    "            h = ax.plot(ds_d_SnowMIP_list[j+1][i].albsn.sel(time=period).where(ds_d_SnowMIP_list[j+1][i].albsn > lim_alb) \\\n",
    "                        .where(ds_d_SnowMIP_list[0][i].albsn < lim_alb_sup)\\\n",
    "                        .where(ds_d_SnowMIP_list[j+1][i].snd > 0.1).where(mask_obs).groupby('time.dayofyear').mean()\\\n",
    "                        .sel(dayofyear=slice(1,365)).roll(dayofyear=doy), label=exp, lw=1)\n",
    "            h_exps.append(h)\n",
    "\n",
    "        # if site.name in [site_SnowMIP.name for site_SnowMIP in SnowMIP_sites]:\n",
    "        #     h_paul = ax.plot(ds_d_Paul_list[i].albsn.sel(time=period).where(ds_d_Paul_list[i].albsn > lim_alb) \\\n",
    "        #                     .where(ds_d_Paul_list[i].albsn < lim_alb_sup)\\\n",
    "        #                     .where(ds_d_Paul_list[i].snd > 0.1).where(mask_obs).groupby('time.dayofyear').mean()\\\n",
    "        #                     .sel(dayofyear=slice(1,365)).roll(dayofyear=doy), label='CLASS', color='red9', zorder=9, lw=1)\n",
    "        if site not in ['umt', 'byl']:\n",
    "            obs = ds_d_Obs_list[i].albs.sel(time=period).where(mask_obs).groupby('time.dayofyear').mean()\\\n",
    "                    .sel(dayofyear=slice(1,365)).roll(dayofyear=doy)\n",
    "            h_obs = ax.plot(obs, label='Obs', color=color_obs, lw=0.8, zorder=10)\n",
    "            ax.format(ylabel='', ylim=(0.4,0.9),\n",
    "                      lltitle=str(ds_d_Obs_list[i].sel(time=period).albs.dropna(dim='time').time[0].values)[:10]+' to\\n'+ \\\n",
    "                      str(ds_d_Obs_list[i].sel(time=period).albs.dropna(dim='time').time[-1].values)[:10]) \n",
    "\n",
    "    else:\n",
    "        shadedata = ds_d_SnowMIP_list[0][i].albsn.sel(time=period).where(ds_d_SnowMIP_list[0][i].albsn > lim_alb) \\\n",
    "                    .where(ds_d_SnowMIP_list[0][i].albsn < lim_alb_sup)\\\n",
    "                    .where(ds_d_SnowMIP_list[0][i].snd > 0.1).groupby('time.dayofyear').quantile([0.1, 0.9])\\\n",
    "                    .sel(dayofyear=slice(1,365)).roll(dayofyear=doy).transpose('quantile', 'dayofyear')\n",
    "        h1 = ax.plot(ds_d_SnowMIP_list[0][i].albsn.sel(time=period).where(ds_d_SnowMIP_list[0][i].albsn > lim_alb) \\\n",
    "                    .where(ds_d_SnowMIP_list[0][i].albsn < lim_alb_sup)\\\n",
    "                     .where(ds_d_SnowMIP_list[0][i].snd > 0.1).groupby('time.dayofyear').mean()\\\n",
    "                     .sel(dayofyear=slice(1,365)).roll(dayofyear=doy), shadedata=shadedata, label=exps[0], zorder=1, lw=1)\n",
    "        h_exps = []\n",
    "        for j, exp in enumerate(exps[1:]):\n",
    "            h = ax.plot(ds_d_SnowMIP_list[j+1][i].albsn.sel(time=period).where(ds_d_SnowMIP_list[j+1][i].albsn > lim_alb) \\\n",
    "                        .where(ds_d_SnowMIP_list[0][i].albsn < lim_alb_sup)\\\n",
    "                        .where(ds_d_SnowMIP_list[j+1][i].snd > 0.1).groupby('time.dayofyear').mean()\\\n",
    "                        .sel(dayofyear=slice(1,365)).roll(dayofyear=doy), label=exp, lw=1)\n",
    "            h_exps.append(h)\n",
    "\n",
    "        # if site.name in [site_SnowMIP.name for site_SnowMIP in SnowMIP_sites]:\n",
    "        #     h_paul = ax.plot(ds_d_Paul_list[i].albsn.sel(time=period).where(ds_d_Paul_list[i].albsn > lim_alb) \\\n",
    "        #                      .where(ds_d_SnowMIP_list[0][i].albsn < lim_alb_sup)\\\n",
    "        #                     .where(ds_d_Paul_list[i].snd > 0.1).groupby('time.dayofyear').mean()\\\n",
    "        #                     .sel(dayofyear=slice(1,365)).roll(dayofyear=doy), label='CLASS', color='red9', zorder=9, lw=1)\n",
    "        \n",
    "        ax.format(ylabel='', ylim=(0.4,0.9), lltitle=period.start+' to\\n'+ period.stop)\n",
    "    \n",
    "    \n",
    "    # Surface temperature\n",
    "    # Add condition on ts <= 0 on obs to avoid melting pachy areas to be counted\n",
    "    ax = axs[i*5+3]\n",
    "\n",
    "    if 'ts' in list(ds_d_Obs_list[i].keys()) and ds_d_Obs_list[i].ts.notnull().sum() != 0:\n",
    "        mask_obs = ~ds_d_Obs_list[i].ts.sel(time=period).where(ds_d_Obs_list[i].ts <= 0)\\\n",
    "                    .where(ds_d_Obs_list[i].snd_auto > 0.1).isnull()\n",
    "        \n",
    "        shadedata = ds_d_SnowMIP_list[0][i].ts.sel(time=period).where(ds_d_SnowMIP_list[0][i].snd > 0.1).where(mask_obs)\\\n",
    "                    .groupby('time.dayofyear').quantile([0.1, 0.9]).sel(dayofyear=slice(1,365)).roll(dayofyear=doy)\\\n",
    "                    .transpose('quantile', 'dayofyear')-273.15\n",
    "        h1 = ax.plot(ds_d_SnowMIP_list[0][i].ts.sel(time=period).where(ds_d_SnowMIP_list[0][i].snd > 0.1).where(mask_obs)\\\n",
    "                     .groupby('time.dayofyear').mean().sel(dayofyear=slice(1,365))\\\n",
    "                     .roll(dayofyear=doy)-273.15, shadedata=shadedata, label=exps[0], zorder=1, lw=1)\n",
    "        h_exps = []\n",
    "        for j, exp in enumerate(exps[1:]):\n",
    "            h = ax.plot(ds_d_SnowMIP_list[j+1][i].ts.sel(time=period).where(ds_d_SnowMIP_list[j+1][i].snd > 0.1)\\\n",
    "                        .where(mask_obs).groupby('time.dayofyear').mean().sel(dayofyear=slice(1,365))\\\n",
    "                        .roll(dayofyear=doy)-273.15, label=exp, lw=1)\n",
    "            h_exps.append(h)\n",
    "\n",
    "        # if site.name in [site_SnowMIP.name for site_SnowMIP in SnowMIP_sites]:\n",
    "        #     h_paul = ax.plot(ds_d_Paul_list[i].ts.sel(time=period).where(ds_d_Paul_list[i].snd > 0.1).where(mask_obs)\\\n",
    "        #                      .groupby('time.dayofyear').mean().sel(dayofyear=slice(1,365))\\\n",
    "        #                      .roll(dayofyear=doy)-273.15, label='CLASS', color='red9', zorder=9, lw=1)\n",
    "        \n",
    "        obs = ds_d_Obs_list[i].ts.sel(time=period).where(mask_obs).groupby('time.dayofyear').mean()\\\n",
    "                .sel(dayofyear=slice(1,365)).roll(dayofyear=doy)\n",
    "        h_obs = ax.plot(obs, label='Obs', color=color_obs, lw=0.8, zorder=10)\n",
    "        ax.format(ylabel='', ylim=(-48,2),\n",
    "                  lltitle=str(ds_d_Obs_list[i].sel(time=period).ts.dropna(dim='time').time[0].values)[:10]+' to\\n'+ \\\n",
    "                  str(ds_d_Obs_list[i].sel(time=period).ts.dropna(dim='time').time[-1].values)[:10]) \n",
    "\n",
    "    else:\n",
    "        shadedata = ds_d_SnowMIP_list[0][i].ts.sel(time=period).where(ds_d_SnowMIP_list[0][i].snd > 0.1)\\\n",
    "                    .groupby('time.dayofyear').quantile([0.1, 0.9]).sel(dayofyear=slice(1,365)).roll(dayofyear=doy)\\\n",
    "                    .transpose('quantile', 'dayofyear')-273.15\n",
    "        h1 = ax.plot(ds_d_SnowMIP_list[0][i].ts.sel(time=period).where(ds_d_SnowMIP_list[0][i].snd > 0.1)\\\n",
    "                     .groupby('time.dayofyear').mean().sel(dayofyear=slice(1,365))\\\n",
    "                     .roll(dayofyear=doy)-273.15, shadedata=shadedata, label=exps[0], zorder=1, lw=1)\n",
    "        h_exps = []\n",
    "        for j, exp in enumerate(exps[1:]):\n",
    "            h = ax.plot(ds_d_SnowMIP_list[j+1][i].ts.sel(time=period).where(ds_d_SnowMIP_list[j+1][i].snd > 0.1)\\\n",
    "                        .groupby('time.dayofyear').mean().sel(dayofyear=slice(1,365))\\\n",
    "                        .roll(dayofyear=doy)-273.15, label=exp, lw=1)\n",
    "            h_exps.append(h)\n",
    "\n",
    "        # if site.name in [site_SnowMIP.name for site_SnowMIP in SnowMIP_sites]:\n",
    "        #     h_paul = ax.plot(ds_d_Paul_list[i].ts.sel(time=period).where(ds_d_Paul_list[i].snd > 0.1)\\\n",
    "        #                      .groupby('time.dayofyear').mean().sel(dayofyear=slice(1,365))\\\n",
    "        #                      .roll(dayofyear=doy)-273.15, label='CLASS', color='red9', zorder=9, lw=1)\n",
    "        \n",
    "        ax.format(ylabel='', ylim=(-48,2), lltitle=period.start+' to\\n'+ period.stop)\n",
    "\n",
    "    \n",
    "    # Soil temperature\n",
    "    ax = axs[i*5+4]\n",
    "\n",
    "    if 'tsl' in list(ds_d_Obs_list[i].keys()):\n",
    "        \n",
    "        # Get the first soil layer from obs (except for byl)\n",
    "        if site.name == 'byl':\n",
    "            obs_sdepth = ds_d_Obs_list[i].tsl.sdepth[1].values.item(0) # 0.05 instead of 0.02\n",
    "        else:\n",
    "            obs_sdepth = ds_d_Obs_list[i].tsl.sdepth[0].values.item(0)\n",
    "\n",
    "        # For wfj (otherwise NaN so take the first model level)\n",
    "        if obs_sdepth < 0.01: \n",
    "            model_sdepth = 0.05\n",
    "        else:\n",
    "            model_sdepth = obs_sdepth\n",
    "        mask_obs = ~ds_d_Obs_list[i].tsl.sel(time=period, sdepth=obs_sdepth).where(ds_d_Obs_list[i].snd_auto > 0.1).isnull()\n",
    "\n",
    "        # Interp model on the first soil layer obs\n",
    "        if obs_sdepth < 0.01: \n",
    "            ds_d_interp = ds_d_SnowMIP_list[0][i]\n",
    "        else:\n",
    "            ds_d_interp = ds_d_SnowMIP_list[0][i].interp(layer=ds_d_Obs_list[i].tsl.sdepth.values)\n",
    "        \n",
    "        shadedata = ds_d_interp.tsl.sel(time=period, layer=model_sdepth).where(ds_d_SnowMIP_list[0][i].snd > 0.1).where(mask_obs)\\\n",
    "                    .groupby('time.dayofyear').quantile([0.1, 0.9]).sel(dayofyear=slice(1,365)).roll(dayofyear=doy)\\\n",
    "                    .transpose('quantile', 'dayofyear')-273.15\n",
    "        h1 = ax.plot(ds_d_interp.tsl.sel(time=period, layer=model_sdepth).where(ds_d_SnowMIP_list[0][i].snd > 0.1).where(mask_obs)\\\n",
    "                     .groupby('time.dayofyear').mean().sel(dayofyear=slice(1,365))\\\n",
    "                     .roll(dayofyear=doy)-273.15, shadedata=shadedata, label=exps[0], zorder=1, lw=1)\n",
    "        h_exps = []\n",
    "        for j, exp in enumerate(exps[1:]):\n",
    "            if obs_sdepth < 0.01: \n",
    "                ds_d_interp = ds_d_SnowMIP_list[j+1][i]\n",
    "            else:\n",
    "                ds_d_interp = ds_d_SnowMIP_list[j+1][i].interp(layer=ds_d_Obs_list[i].tsl.sdepth.values)\n",
    "            \n",
    "            h = ax.plot(ds_d_interp.tsl.sel(time=period, layer=model_sdepth).where(ds_d_SnowMIP_list[j+1][i].snd > 0.1)\\\n",
    "                        .where(mask_obs).groupby('time.dayofyear').mean().sel(dayofyear=slice(1,365))\\\n",
    "                        .roll(dayofyear=doy)-273.15, label=exp, lw=1)\n",
    "            h_exps.append(h)\n",
    "\n",
    "        # if site.name in [site_SnowMIP.name for site_SnowMIP in SnowMIP_sites]:\n",
    "        #     if obs_sdepth < 0.01: \n",
    "        #         ds_d_interp = ds_d_Paul_list[i].interp(layer=ds_d_SnowMIP_list[0][i].tsl.layer.values)\n",
    "        #     else:\n",
    "        #         ds_d_interp = ds_d_Paul_list[i].interp(layer=ds_d_Obs_list[i].tsl.sdepth.values)\n",
    "        #     h_paul = ax.plot(ds_d_interp.tsl.sel(time=period, layer=model_sdepth).where(ds_d_Paul_list[i].snd > 0.1).where(mask_obs)\\\n",
    "        #                      .groupby('time.dayofyear').mean().sel(dayofyear=slice(1,365))\\\n",
    "        #                      .roll(dayofyear=doy)-273.15, label='CLASS', color='red9', zorder=9, lw=1)\n",
    "\n",
    "        obs = ds_d_Obs_list[i].tsl.sel(time=period, sdepth=obs_sdepth).where(mask_obs).groupby('time.dayofyear').mean()\\\n",
    "                .sel(dayofyear=slice(1,365)).roll(dayofyear=doy)\n",
    "        shadedata = np.concatenate((np.expand_dims(obs.values+0.4, axis=0), np.expand_dims(obs.values-0.4, axis=0),), axis=0)\n",
    "        h_obs = ax.plot(obs, label='Obs', shadedata=shadedata, color=color_obs, lw=0.8, zorder=10)\n",
    "        ax.hlines(0, 1, 365, c='gray', lw=0.5, alpha=0.3)\n",
    "        if site.name == 'byl':\n",
    "            ylim=(-30, 10)\n",
    "        else:\n",
    "            ylim=(-30, 10)\n",
    "            # ylim=(-5, 10)\n",
    "        if obs_sdepth != model_sdepth: \n",
    "            ax.format(ylabel='', ylim=ylim,\n",
    "                      lltitle=str(ds_d_Obs_list[i].tsl.sel(time=period, sdepth=obs_sdepth).dropna(dim='time').time[0].values)[:10]+' to\\n'+ \\\n",
    "                      str(ds_d_Obs_list[i].tsl.sel(time=period, sdepth=obs_sdepth).dropna(dim='time').time[-1].values)[:10]+' ('+\\\n",
    "                         str(round(obs_sdepth*100))+' / '+str(round(model_sdepth*100))+' cm)') \n",
    "        else:\n",
    "            ax.format(ylabel='', ylim=ylim,\n",
    "                      lltitle=str(ds_d_Obs_list[i].tsl.sel(time=period, sdepth=obs_sdepth).dropna(dim='time').time[0].values)[:10]+' to\\n'+ \\\n",
    "                      str(ds_d_Obs_list[i].tsl.sel(time=period, sdepth=obs_sdepth).dropna(dim='time').time[-1].values)[:10]+' ('+\\\n",
    "                         str(round(obs_sdepth*100))+' cm)')\n",
    "\n",
    "    else:\n",
    "        model_sdepth = 0.05 # first level\n",
    "        \n",
    "        shadedata = ds_d_SnowMIP_list[0][i].tsl.sel(time=period, layer=model_sdepth).where(ds_d_SnowMIP_list[0][i].snd > 0.1)\\\n",
    "                    .groupby('time.dayofyear').quantile([0.1, 0.9]).sel(dayofyear=slice(1,365)).roll(dayofyear=doy)\\\n",
    "                    .transpose('quantile', 'dayofyear')-273.15\n",
    "        h1 = ax.plot(ds_d_SnowMIP_list[0][i].tsl.sel(time=period, layer=model_sdepth).where(ds_d_SnowMIP_list[0][i].snd > 0.1)\\\n",
    "                     .groupby('time.dayofyear').mean().sel(dayofyear=slice(1,365))\\\n",
    "                     .roll(dayofyear=doy)-273.15, shadedata=shadedata, label=exps[0], zorder=1, lw=1)\n",
    "        h_exps = []\n",
    "        for j, exp in enumerate(exps[1:]):            \n",
    "            h = ax.plot(ds_d_SnowMIP_list[j+1][i].tsl.sel(time=period, layer=model_sdepth).where(ds_d_SnowMIP_list[j+1][i].snd > 0.1)\\\n",
    "                        .groupby('time.dayofyear').mean().sel(dayofyear=slice(1,365))\\\n",
    "                        .roll(dayofyear=doy)-273.15, label=exp, lw=1)\n",
    "            h_exps.append(h)\n",
    "\n",
    "        # if site.name in [site_SnowMIP.name for site_SnowMIP in SnowMIP_sites]:\n",
    "        #     ds_d_interp = ds_d_Paul_list[i].interp(layer=ds_d_SnowMIP_list[0][i].tsl.layer.values)\n",
    "        #     h_paul = ax.plot(ds_d_interp.tsl.sel(time=period, layer=model_sdepth).where(ds_d_Paul_list[i].snd > 0.1)\\\n",
    "        #                      .groupby('time.dayofyear').mean().sel(dayofyear=slice(1,365))\\\n",
    "        #                      .roll(dayofyear=doy)-273.15, label='CLASS', color='red9', zorder=9, lw=1)\n",
    "\n",
    "        ax.hlines(0, 1, 365, c='gray', lw=0.5, alpha=0.3)\n",
    "        ax.format(ylabel='', ylim=ylim, lltitle=period.start+' to\\n'+ period.stop+' ('+\\\n",
    "                     str(round(model_sdepth*100))+' cm)')\n",
    "    \n",
    "    \n",
    "# for ax in axs:\n",
    "#     ax.format(xlim=(40,350))\n",
    "    \n",
    "fig.format(abc='(a)', abcloc='ur', \n",
    "           collabels=['Snow Depth [m]', 'SWE [mm]', 'Albedo\\n (SD > 10 cm)', 'Surf temp [°C]\\n (SD > 10 cm)', \n",
    "                      'Soil temp [°C]\\n (SD > 10 cm)'],\n",
    "           rowlabels=[site.name for site in SnowMIP_sites+SnowArctic_sites])\n",
    "# fig.legend(h1+h_exps+h_paul+h_obs, loc='b', ncols=2)\n",
    "fig.legend(h1+h_exps+h_obs, loc='b', ncols=5)\n",
    "\n",
    "# fig.save('img/mtr_ac_phys.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_exps = [\n",
    "#     # 'Ref_30min_ext',\n",
    "#     'DEF',\n",
    "#     'BUG_CORRECT',\n",
    "#     'BUG_CORRECT_TSNBT_OP1',\n",
    "#     'BUG_CORRECT_TSNBT_OP1_EZERO',\n",
    "\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# color_obs = 'gray8'\n",
    "\n",
    "# list_exps = []\n",
    "# for k, exps in enumerate(all_exps):\n",
    "#     list_exps.append(exps)\n",
    "#     exps = list_exps\n",
    "#     # fig, axs = pplt.subplots(ncols=5, nrows=len(SnowMIP_sites+SnowArctic_sites), refwidth=1.5, sharey=0)\n",
    "#     fig, axs = pplt.subplots(ncols=5, nrows=len(SnowMIP_sites+SnowArctic_sites), refwidth=1.5, sharey=0, hspace=1, refaspect=1.4)\n",
    "    \n",
    "#     # for i, site in enumerate([cdp]):\n",
    "#     for i, site in enumerate(SnowMIP_sites+SnowArctic_sites):\n",
    "    \n",
    "#         doy = 140\n",
    "#         period = site.period_used\n",
    "    \n",
    "#         # Snow depth\n",
    "#         ax = axs[i*5+0]\n",
    "#         mask_obs = ~ds_d_Obs_list[i].snd_auto.sel(time=period).isnull()\n",
    "        \n",
    "#         shadedata = ds_d_SnowMIP_list[0][i].snd.sel(time=period).where(mask_obs).groupby('time.dayofyear').quantile([0.1, 0.9])\\\n",
    "#                     .sel(dayofyear=slice(1,365)).roll(dayofyear=doy).transpose('quantile', 'dayofyear')\n",
    "#         h1 = ax.plot(ds_d_SnowMIP_list[0][i].snd.sel(time=period).where(mask_obs).groupby('time.dayofyear').mean()\\\n",
    "#                      .sel(dayofyear=slice(1,365)).roll(dayofyear=doy), shadedata=shadedata, label=exps[0], zorder=1, lw=1)\n",
    "#         h_exps = []\n",
    "#         for j, exp in enumerate(exps[1:]):\n",
    "#             h = ax.plot(ds_d_SnowMIP_list[j+1][i].snd.sel(time=period).where(mask_obs).groupby('time.dayofyear').mean()\\\n",
    "#                      .sel(dayofyear=slice(1,365)).roll(dayofyear=doy), label=exp, lw=1)\n",
    "#             h_exps.append(h)\n",
    "    \n",
    "#         # if site.name in [site_SnowMIP.name for site_SnowMIP in SnowMIP_sites]:\n",
    "#         #     h_paul = ax.plot(ds_d_Paul_list[i].snd.sel(time=period).where(mask_obs).groupby('time.dayofyear').mean()\\\n",
    "#         #                  .sel(dayofyear=slice(1,365)).roll(dayofyear=doy), label='CLASS', color='red9', zorder=9, lw=1)\n",
    "        \n",
    "#         obs = ds_d_Obs_list[i].snd_auto.sel(time=period).groupby('time.dayofyear').mean().sel(dayofyear=slice(1,365)).roll(dayofyear=doy)\n",
    "#         shadedata = np.concatenate((np.expand_dims(obs.values+0.1, axis=0), np.expand_dims(obs.values-0.1, axis=0),), axis=0)\n",
    "#         h_obs = ax.plot(obs, shadedata=shadedata, label='Obs', color=color_obs, lw=0.8, zorder=10)\n",
    "#         ax.format(ylabel='', ylim=(-0.2,3),\n",
    "#                   ultitle=str(ds_d_Obs_list[i].sel(time=period).snd_auto.dropna(dim='time').time[0].values)[:10]+' to\\n'+ \\\n",
    "#                   str(ds_d_Obs_list[i].sel(time=period).snd_auto.dropna(dim='time').time[-1].values)[:10])    \n",
    "#         # ax.legend(h1+h_exps+h_paul+h_obs, loc='ul', ncols=1)\n",
    "        \n",
    "#         # Snow Water Equivalent\n",
    "#         ax = axs[i*5+1]\n",
    "    \n",
    "#         if 'snw_auto' in list(ds_d_Obs_list[i].keys()):\n",
    "#             mask_obs = ~ds_d_Obs_list[i].snw_auto.sel(time=period).isnull()\n",
    "            \n",
    "#             shadedata = ds_d_SnowMIP_list[0][i].snw.sel(time=period).where(mask_obs).groupby('time.dayofyear').quantile([0.1, 0.9])\\\n",
    "#                         .sel(dayofyear=slice(1,365)).roll(dayofyear=doy).transpose('quantile', 'dayofyear')\n",
    "#             h1 = ax.plot(ds_d_SnowMIP_list[0][i].snw.sel(time=period).where(mask_obs).groupby('time.dayofyear').mean()\\\n",
    "#                          .sel(dayofyear=slice(1,365)).roll(dayofyear=doy), shadedata=shadedata, label=exps[0], zorder=1, lw=1)\n",
    "#             h_exps = []\n",
    "#             for j, exp in enumerate(exps[1:]):\n",
    "#                 h = ax.plot(ds_d_SnowMIP_list[j+1][i].snw.sel(time=period).where(mask_obs).groupby('time.dayofyear').mean()\\\n",
    "#                          .sel(dayofyear=slice(1,365)).roll(dayofyear=doy), label=exp, lw=1)\n",
    "#                 h_exps.append(h)\n",
    "    \n",
    "#             # if site.name in [site_SnowMIP.name for site_SnowMIP in SnowMIP_sites]:\n",
    "#             #     h_paul = ax.plot(ds_d_Paul_list[i].snw.sel(time=period).where(mask_obs).groupby('time.dayofyear').mean()\\\n",
    "#             #                  .sel(dayofyear=slice(1,365)).roll(dayofyear=doy), label='CLASS', color='red9', zorder=9, lw=1)\n",
    "            \n",
    "#             obs = ds_d_Obs_list[i].snw_auto.sel(time=period).groupby('time.dayofyear').mean().sel(dayofyear=slice(1,365)).roll(dayofyear=doy)\n",
    "#             shadedata = np.concatenate((np.expand_dims(obs.values+25, axis=0), np.expand_dims(obs.values-25, axis=0),), axis=0)\n",
    "#             h_obs = ax.plot(obs, shadedata=shadedata, label='Obs', color=color_obs, lw=0.8, zorder=10)\n",
    "#             ax.format(ylabel='', ylim=(-40,1200),\n",
    "#                       ultitle=str(ds_d_Obs_list[i].sel(time=period).snw_auto.dropna(dim='time').time[0].values)[:10]+' to\\n'+ \\\n",
    "#                       str(ds_d_Obs_list[i].sel(time=period).snw_auto.dropna(dim='time').time[-1].values)[:10]) \n",
    "    \n",
    "#         else:\n",
    "#             shadedata = ds_d_SnowMIP_list[0][i].snw.sel(time=period).groupby('time.dayofyear').quantile([0.1, 0.9])\\\n",
    "#                         .sel(dayofyear=slice(1,365)).roll(dayofyear=doy).transpose('quantile', 'dayofyear')\n",
    "#             h1 = ax.plot(ds_d_SnowMIP_list[0][i].snw.sel(time=period).groupby('time.dayofyear').mean()\\\n",
    "#                          .sel(dayofyear=slice(1,365)).roll(dayofyear=doy), shadedata=shadedata, label=exps[0], zorder=1, lw=1)\n",
    "#             h_exps = []\n",
    "#             for j, exp in enumerate(exps[1:]):\n",
    "#                 h = ax.plot(ds_d_SnowMIP_list[j+1][i].snw.sel(time=period).groupby('time.dayofyear').mean()\\\n",
    "#                          .sel(dayofyear=slice(1,365)).roll(dayofyear=doy), label=exp, lw=1)\n",
    "#                 h_exps.append(h)\n",
    "    \n",
    "#             # if site.name in [site_SnowMIP.name for site_SnowMIP in SnowMIP_sites]:\n",
    "#             #     h_paul = ax.plot(ds_d_Paul_list[i].snw.sel(time=period).groupby('time.dayofyear').mean()\\\n",
    "#             #                  .sel(dayofyear=slice(1,365)).roll(dayofyear=doy), label='CLASS', color='red9', zorder=9, lw=1)\n",
    "            \n",
    "#             ax.format(ylabel='', ylim=(-40,1200), ultitle=period.start+' to\\n'+ period.stop)\n",
    "    \n",
    "    \n",
    "#         # Albedo (need to add a condition albsn > 0.4 because a few values are 0 in the model -> bug? (e.g., at Saporo)\n",
    "#         # + low values are observed in the begining of the season (probably due to not full SCF coveraged)\n",
    "#         ax = axs[i*5+2]\n",
    "#         lim_alb = 0.4\n",
    "#         lim_alb_sup = 0.9\n",
    "    \n",
    "#         if 'albs' in list(ds_d_Obs_list[i].keys()):\n",
    "#             mask_obs = ~ds_d_Obs_list[i].albs.where(ds_d_Obs_list[i].albs > lim_alb).where(ds_d_Obs_list[i].albs < lim_alb_sup)\\\n",
    "#                         .where(ds_d_Obs_list[i].snd_auto > 0.1).sel(time=period).isnull()\n",
    "            \n",
    "#             shadedata = ds_d_SnowMIP_list[0][i].albsn.sel(time=period).where(ds_d_SnowMIP_list[0][i].albsn > lim_alb) \\\n",
    "#                         .where(ds_d_SnowMIP_list[0][i].albsn < lim_alb_sup)\\\n",
    "#                         .where(ds_d_SnowMIP_list[0][i].snd > 0.1).where(mask_obs).groupby('time.dayofyear').quantile([0.1, 0.9])\\\n",
    "#                         .sel(dayofyear=slice(1,365)).roll(dayofyear=doy).transpose('quantile', 'dayofyear')\n",
    "#             h1 = ax.plot(ds_d_SnowMIP_list[0][i].albsn.sel(time=period).where(ds_d_SnowMIP_list[0][i].albsn > lim_alb) \\\n",
    "#                          .where(ds_d_SnowMIP_list[0][i].albsn < lim_alb_sup)\\\n",
    "#                          .where(ds_d_SnowMIP_list[0][i].snd > 0.1).where(mask_obs).groupby('time.dayofyear').mean()\\\n",
    "#                          .sel(dayofyear=slice(1,365)).roll(dayofyear=doy), shadedata=shadedata, label=exps[0], zorder=1, lw=1)\n",
    "#             h_exps = []\n",
    "#             for j, exp in enumerate(exps[1:]):\n",
    "#                 h = ax.plot(ds_d_SnowMIP_list[j+1][i].albsn.sel(time=period).where(ds_d_SnowMIP_list[j+1][i].albsn > lim_alb) \\\n",
    "#                             .where(ds_d_SnowMIP_list[0][i].albsn < lim_alb_sup)\\\n",
    "#                             .where(ds_d_SnowMIP_list[j+1][i].snd > 0.1).where(mask_obs).groupby('time.dayofyear').mean()\\\n",
    "#                             .sel(dayofyear=slice(1,365)).roll(dayofyear=doy), label=exp, lw=1)\n",
    "#                 h_exps.append(h)\n",
    "    \n",
    "#             # if site.name in [site_SnowMIP.name for site_SnowMIP in SnowMIP_sites]:\n",
    "#             #     h_paul = ax.plot(ds_d_Paul_list[i].albsn.sel(time=period).where(ds_d_Paul_list[i].albsn > lim_alb) \\\n",
    "#             #                     .where(ds_d_Paul_list[i].albsn < lim_alb_sup)\\\n",
    "#             #                     .where(ds_d_Paul_list[i].snd > 0.1).where(mask_obs).groupby('time.dayofyear').mean()\\\n",
    "#             #                     .sel(dayofyear=slice(1,365)).roll(dayofyear=doy), label='CLASS', color='red9', zorder=9, lw=1)\n",
    "#             if site not in ['umt', 'byl']:\n",
    "#                 obs = ds_d_Obs_list[i].albs.sel(time=period).where(mask_obs).groupby('time.dayofyear').mean()\\\n",
    "#                         .sel(dayofyear=slice(1,365)).roll(dayofyear=doy)\n",
    "#                 h_obs = ax.plot(obs, label='Obs', color=color_obs, lw=0.8, zorder=10)\n",
    "#                 ax.format(ylabel='', ylim=(0.4,0.9),\n",
    "#                           lltitle=str(ds_d_Obs_list[i].sel(time=period).albs.dropna(dim='time').time[0].values)[:10]+' to\\n'+ \\\n",
    "#                           str(ds_d_Obs_list[i].sel(time=period).albs.dropna(dim='time').time[-1].values)[:10]) \n",
    "    \n",
    "#         else:\n",
    "#             shadedata = ds_d_SnowMIP_list[0][i].albsn.sel(time=period).where(ds_d_SnowMIP_list[0][i].albsn > lim_alb) \\\n",
    "#                         .where(ds_d_SnowMIP_list[0][i].albsn < lim_alb_sup)\\\n",
    "#                         .where(ds_d_SnowMIP_list[0][i].snd > 0.1).groupby('time.dayofyear').quantile([0.1, 0.9])\\\n",
    "#                         .sel(dayofyear=slice(1,365)).roll(dayofyear=doy).transpose('quantile', 'dayofyear')\n",
    "#             h1 = ax.plot(ds_d_SnowMIP_list[0][i].albsn.sel(time=period).where(ds_d_SnowMIP_list[0][i].albsn > lim_alb) \\\n",
    "#                         .where(ds_d_SnowMIP_list[0][i].albsn < lim_alb_sup)\\\n",
    "#                          .where(ds_d_SnowMIP_list[0][i].snd > 0.1).groupby('time.dayofyear').mean()\\\n",
    "#                          .sel(dayofyear=slice(1,365)).roll(dayofyear=doy), shadedata=shadedata, label=exps[0], zorder=1, lw=1)\n",
    "#             h_exps = []\n",
    "#             for j, exp in enumerate(exps[1:]):\n",
    "#                 h = ax.plot(ds_d_SnowMIP_list[j+1][i].albsn.sel(time=period).where(ds_d_SnowMIP_list[j+1][i].albsn > lim_alb) \\\n",
    "#                             .where(ds_d_SnowMIP_list[0][i].albsn < lim_alb_sup)\\\n",
    "#                             .where(ds_d_SnowMIP_list[j+1][i].snd > 0.1).groupby('time.dayofyear').mean()\\\n",
    "#                             .sel(dayofyear=slice(1,365)).roll(dayofyear=doy), label=exp, lw=1)\n",
    "#                 h_exps.append(h)\n",
    "    \n",
    "#             # if site.name in [site_SnowMIP.name for site_SnowMIP in SnowMIP_sites]:\n",
    "#             #     h_paul = ax.plot(ds_d_Paul_list[i].albsn.sel(time=period).where(ds_d_Paul_list[i].albsn > lim_alb) \\\n",
    "#             #                      .where(ds_d_SnowMIP_list[0][i].albsn < lim_alb_sup)\\\n",
    "#             #                     .where(ds_d_Paul_list[i].snd > 0.1).groupby('time.dayofyear').mean()\\\n",
    "#             #                     .sel(dayofyear=slice(1,365)).roll(dayofyear=doy), label='CLASS', color='red9', zorder=9, lw=1)\n",
    "            \n",
    "#             ax.format(ylabel='', ylim=(0.4,0.9), lltitle=period.start+' to\\n'+ period.stop)\n",
    "        \n",
    "        \n",
    "#         # Surface temperature\n",
    "#         # Add condition on ts <= 0 on obs to avoid melting pachy areas to be counted\n",
    "#         ax = axs[i*5+3]\n",
    "    \n",
    "#         if 'ts' in list(ds_d_Obs_list[i].keys()) and ds_d_Obs_list[i].ts.notnull().sum() != 0:\n",
    "#             mask_obs = ~ds_d_Obs_list[i].ts.sel(time=period).where(ds_d_Obs_list[i].ts <= 0)\\\n",
    "#                         .where(ds_d_Obs_list[i].snd_auto > 0.1).isnull()\n",
    "            \n",
    "#             shadedata = ds_d_SnowMIP_list[0][i].ts.sel(time=period).where(ds_d_SnowMIP_list[0][i].snd > 0.1).where(mask_obs)\\\n",
    "#                         .groupby('time.dayofyear').quantile([0.1, 0.9]).sel(dayofyear=slice(1,365)).roll(dayofyear=doy)\\\n",
    "#                         .transpose('quantile', 'dayofyear')-273.15\n",
    "#             h1 = ax.plot(ds_d_SnowMIP_list[0][i].ts.sel(time=period).where(ds_d_SnowMIP_list[0][i].snd > 0.1).where(mask_obs)\\\n",
    "#                          .groupby('time.dayofyear').mean().sel(dayofyear=slice(1,365))\\\n",
    "#                          .roll(dayofyear=doy)-273.15, shadedata=shadedata, label=exps[0], zorder=1, lw=1)\n",
    "#             h_exps = []\n",
    "#             for j, exp in enumerate(exps[1:]):\n",
    "#                 h = ax.plot(ds_d_SnowMIP_list[j+1][i].ts.sel(time=period).where(ds_d_SnowMIP_list[j+1][i].snd > 0.1)\\\n",
    "#                             .where(mask_obs).groupby('time.dayofyear').mean().sel(dayofyear=slice(1,365))\\\n",
    "#                             .roll(dayofyear=doy)-273.15, label=exp, lw=1)\n",
    "#                 h_exps.append(h)\n",
    "    \n",
    "#             # if site.name in [site_SnowMIP.name for site_SnowMIP in SnowMIP_sites]:\n",
    "#             #     h_paul = ax.plot(ds_d_Paul_list[i].ts.sel(time=period).where(ds_d_Paul_list[i].snd > 0.1).where(mask_obs)\\\n",
    "#             #                      .groupby('time.dayofyear').mean().sel(dayofyear=slice(1,365))\\\n",
    "#             #                      .roll(dayofyear=doy)-273.15, label='CLASS', color='red9', zorder=9, lw=1)\n",
    "            \n",
    "#             obs = ds_d_Obs_list[i].ts.sel(time=period).where(mask_obs).groupby('time.dayofyear').mean()\\\n",
    "#                     .sel(dayofyear=slice(1,365)).roll(dayofyear=doy)\n",
    "#             h_obs = ax.plot(obs, label='Obs', color=color_obs, lw=0.8, zorder=10)\n",
    "#             ax.format(ylabel='', ylim=(-48,2),\n",
    "#                       lltitle=str(ds_d_Obs_list[i].sel(time=period).ts.dropna(dim='time').time[0].values)[:10]+' to\\n'+ \\\n",
    "#                       str(ds_d_Obs_list[i].sel(time=period).ts.dropna(dim='time').time[-1].values)[:10]) \n",
    "    \n",
    "#         else:\n",
    "#             shadedata = ds_d_SnowMIP_list[0][i].ts.sel(time=period).where(ds_d_SnowMIP_list[0][i].snd > 0.1)\\\n",
    "#                         .groupby('time.dayofyear').quantile([0.1, 0.9]).sel(dayofyear=slice(1,365)).roll(dayofyear=doy)\\\n",
    "#                         .transpose('quantile', 'dayofyear')-273.15\n",
    "#             h1 = ax.plot(ds_d_SnowMIP_list[0][i].ts.sel(time=period).where(ds_d_SnowMIP_list[0][i].snd > 0.1)\\\n",
    "#                          .groupby('time.dayofyear').mean().sel(dayofyear=slice(1,365))\\\n",
    "#                          .roll(dayofyear=doy)-273.15, shadedata=shadedata, label=exps[0], zorder=1, lw=1)\n",
    "#             h_exps = []\n",
    "#             for j, exp in enumerate(exps[1:]):\n",
    "#                 h = ax.plot(ds_d_SnowMIP_list[j+1][i].ts.sel(time=period).where(ds_d_SnowMIP_list[j+1][i].snd > 0.1)\\\n",
    "#                             .groupby('time.dayofyear').mean().sel(dayofyear=slice(1,365))\\\n",
    "#                             .roll(dayofyear=doy)-273.15, label=exp, lw=1)\n",
    "#                 h_exps.append(h)\n",
    "    \n",
    "#             # if site.name in [site_SnowMIP.name for site_SnowMIP in SnowMIP_sites]:\n",
    "#             #     h_paul = ax.plot(ds_d_Paul_list[i].ts.sel(time=period).where(ds_d_Paul_list[i].snd > 0.1)\\\n",
    "#             #                      .groupby('time.dayofyear').mean().sel(dayofyear=slice(1,365))\\\n",
    "#             #                      .roll(dayofyear=doy)-273.15, label='CLASS', color='red9', zorder=9, lw=1)\n",
    "            \n",
    "#             ax.format(ylabel='', ylim=(-48,2), lltitle=period.start+' to\\n'+ period.stop)\n",
    "    \n",
    "        \n",
    "#         # Soil temperature\n",
    "#         ax = axs[i*5+4]\n",
    "    \n",
    "#         if 'tsl' in list(ds_d_Obs_list[i].keys()):\n",
    "            \n",
    "#             # Get the first soil layer from obs (except for byl)\n",
    "#             if site.name == 'byl':\n",
    "#                 obs_sdepth = ds_d_Obs_list[i].tsl.sdepth[1].values.item(0) # 0.05 instead of 0.02\n",
    "#             else:\n",
    "#                 obs_sdepth = ds_d_Obs_list[i].tsl.sdepth[0].values.item(0)\n",
    "    \n",
    "#             # For wfj (otherwise NaN so take the first model level)\n",
    "#             if obs_sdepth < 0.01: \n",
    "#                 model_sdepth = 0.05\n",
    "#             else:\n",
    "#                 model_sdepth = obs_sdepth\n",
    "#             mask_obs = ~ds_d_Obs_list[i].tsl.sel(time=period, sdepth=obs_sdepth).where(ds_d_Obs_list[i].snd_auto > 0.1).isnull()\n",
    "    \n",
    "#             # Interp model on the first soil layer obs\n",
    "#             if obs_sdepth < 0.01: \n",
    "#                 ds_d_interp = ds_d_SnowMIP_list[0][i]\n",
    "#             else:\n",
    "#                 ds_d_interp = ds_d_SnowMIP_list[0][i].interp(layer=ds_d_Obs_list[i].tsl.sdepth.values)\n",
    "            \n",
    "#             shadedata = ds_d_interp.tsl.sel(time=period, layer=model_sdepth).where(ds_d_SnowMIP_list[0][i].snd > 0.1).where(mask_obs)\\\n",
    "#                         .groupby('time.dayofyear').quantile([0.1, 0.9]).sel(dayofyear=slice(1,365)).roll(dayofyear=doy)\\\n",
    "#                         .transpose('quantile', 'dayofyear')-273.15\n",
    "#             h1 = ax.plot(ds_d_interp.tsl.sel(time=period, layer=model_sdepth).where(ds_d_SnowMIP_list[0][i].snd > 0.1).where(mask_obs)\\\n",
    "#                          .groupby('time.dayofyear').mean().sel(dayofyear=slice(1,365))\\\n",
    "#                          .roll(dayofyear=doy)-273.15, shadedata=shadedata, label=exps[0], zorder=1, lw=1)\n",
    "#             h_exps = []\n",
    "#             for j, exp in enumerate(exps[1:]):\n",
    "#                 if obs_sdepth < 0.01: \n",
    "#                     ds_d_interp = ds_d_SnowMIP_list[j+1][i]\n",
    "#                 else:\n",
    "#                     ds_d_interp = ds_d_SnowMIP_list[j+1][i].interp(layer=ds_d_Obs_list[i].tsl.sdepth.values)\n",
    "                \n",
    "#                 h = ax.plot(ds_d_interp.tsl.sel(time=period, layer=model_sdepth).where(ds_d_SnowMIP_list[j+1][i].snd > 0.1)\\\n",
    "#                             .where(mask_obs).groupby('time.dayofyear').mean().sel(dayofyear=slice(1,365))\\\n",
    "#                             .roll(dayofyear=doy)-273.15, label=exp, lw=1)\n",
    "#                 h_exps.append(h)\n",
    "    \n",
    "#             # if site.name in [site_SnowMIP.name for site_SnowMIP in SnowMIP_sites]:\n",
    "#             #     if obs_sdepth < 0.01: \n",
    "#             #         ds_d_interp = ds_d_Paul_list[i].interp(layer=ds_d_SnowMIP_list[0][i].tsl.layer.values)\n",
    "#             #     else:\n",
    "#             #         ds_d_interp = ds_d_Paul_list[i].interp(layer=ds_d_Obs_list[i].tsl.sdepth.values)\n",
    "#             #     h_paul = ax.plot(ds_d_interp.tsl.sel(time=period, layer=model_sdepth).where(ds_d_Paul_list[i].snd > 0.1).where(mask_obs)\\\n",
    "#             #                      .groupby('time.dayofyear').mean().sel(dayofyear=slice(1,365))\\\n",
    "#             #                      .roll(dayofyear=doy)-273.15, label='CLASS', color='red9', zorder=9, lw=1)\n",
    "    \n",
    "#             obs = ds_d_Obs_list[i].tsl.sel(time=period, sdepth=obs_sdepth).where(mask_obs).groupby('time.dayofyear').mean()\\\n",
    "#                     .sel(dayofyear=slice(1,365)).roll(dayofyear=doy)\n",
    "#             shadedata = np.concatenate((np.expand_dims(obs.values+0.4, axis=0), np.expand_dims(obs.values-0.4, axis=0),), axis=0)\n",
    "#             h_obs = ax.plot(obs, label='Obs', shadedata=shadedata, color=color_obs, lw=0.8, zorder=10)\n",
    "#             ax.hlines(0, 1, 365, c='gray', lw=0.5, alpha=0.3)\n",
    "#             if site.name == 'byl':\n",
    "#                 ylim=(-30, 10)\n",
    "#             else:\n",
    "#                 ylim=(-30, 10)\n",
    "#                 # ylim=(-5, 10)\n",
    "#             if obs_sdepth != model_sdepth: \n",
    "#                 ax.format(ylabel='', ylim=ylim,\n",
    "#                           lltitle=str(ds_d_Obs_list[i].tsl.sel(time=period, sdepth=obs_sdepth).dropna(dim='time').time[0].values)[:10]+' to\\n'+ \\\n",
    "#                           str(ds_d_Obs_list[i].tsl.sel(time=period, sdepth=obs_sdepth).dropna(dim='time').time[-1].values)[:10]+' ('+\\\n",
    "#                              str(round(obs_sdepth*100))+' / '+str(round(model_sdepth*100))+' cm)') \n",
    "#             else:\n",
    "#                 ax.format(ylabel='', ylim=ylim,\n",
    "#                           lltitle=str(ds_d_Obs_list[i].tsl.sel(time=period, sdepth=obs_sdepth).dropna(dim='time').time[0].values)[:10]+' to\\n'+ \\\n",
    "#                           str(ds_d_Obs_list[i].tsl.sel(time=period, sdepth=obs_sdepth).dropna(dim='time').time[-1].values)[:10]+' ('+\\\n",
    "#                              str(round(obs_sdepth*100))+' cm)')\n",
    "    \n",
    "#         else:\n",
    "#             model_sdepth = 0.05 # first level\n",
    "            \n",
    "#             shadedata = ds_d_SnowMIP_list[0][i].tsl.sel(time=period, layer=model_sdepth).where(ds_d_SnowMIP_list[0][i].snd > 0.1)\\\n",
    "#                         .groupby('time.dayofyear').quantile([0.1, 0.9]).sel(dayofyear=slice(1,365)).roll(dayofyear=doy)\\\n",
    "#                         .transpose('quantile', 'dayofyear')-273.15\n",
    "#             h1 = ax.plot(ds_d_SnowMIP_list[0][i].tsl.sel(time=period, layer=model_sdepth).where(ds_d_SnowMIP_list[0][i].snd > 0.1)\\\n",
    "#                          .groupby('time.dayofyear').mean().sel(dayofyear=slice(1,365))\\\n",
    "#                          .roll(dayofyear=doy)-273.15, shadedata=shadedata, label=exps[0], zorder=1, lw=1)\n",
    "#             h_exps = []\n",
    "#             for j, exp in enumerate(exps[1:]):            \n",
    "#                 h = ax.plot(ds_d_SnowMIP_list[j+1][i].tsl.sel(time=period, layer=model_sdepth).where(ds_d_SnowMIP_list[j+1][i].snd > 0.1)\\\n",
    "#                             .groupby('time.dayofyear').mean().sel(dayofyear=slice(1,365))\\\n",
    "#                             .roll(dayofyear=doy)-273.15, label=exp, lw=1)\n",
    "#                 h_exps.append(h)\n",
    "    \n",
    "#             # if site.name in [site_SnowMIP.name for site_SnowMIP in SnowMIP_sites]:\n",
    "#             #     ds_d_interp = ds_d_Paul_list[i].interp(layer=ds_d_SnowMIP_list[0][i].tsl.layer.values)\n",
    "#             #     h_paul = ax.plot(ds_d_interp.tsl.sel(time=period, layer=model_sdepth).where(ds_d_Paul_list[i].snd > 0.1)\\\n",
    "#             #                      .groupby('time.dayofyear').mean().sel(dayofyear=slice(1,365))\\\n",
    "#             #                      .roll(dayofyear=doy)-273.15, label='CLASS', color='red9', zorder=9, lw=1)\n",
    "    \n",
    "#             ax.hlines(0, 1, 365, c='gray', lw=0.5, alpha=0.3)\n",
    "#             ax.format(ylabel='', ylim=ylim, lltitle=period.start+' to\\n'+ period.stop+' ('+\\\n",
    "#                          str(round(model_sdepth*100))+' cm)')\n",
    "        \n",
    "        \n",
    "#     # for ax in axs:\n",
    "#     #     ax.format(xlim=(40,350))\n",
    "        \n",
    "#     fig.format(abc='(a)', abcloc='ur', \n",
    "#                collabels=['Snow Depth [m]', 'SWE [mm]', 'Albedo\\n (SD > 10 cm)', 'Surf temp [°C]\\n (SD > 10 cm)', \n",
    "#                           'Soil temp [°C]\\n (SD > 10 cm)'],\n",
    "#                rowlabels=[site.name for site in SnowMIP_sites+SnowArctic_sites])\n",
    "#     # fig.legend(h1+h_exps+h_paul+h_obs, loc='b', ncols=2)\n",
    "#     fig.legend(h1+h_exps+h_obs, loc='b', ncols=5)\n",
    "    \n",
    "    # fig.save('img/mtr_ac_phys_'+str(k)+'.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exps = [\n",
    "#     # 'Ref_30min_ext',\n",
    "#     'DEF',\n",
    "#     'BUG_CORRECT',\n",
    "#     'BUG_CORRECT_TSNBT_OP1',\n",
    "#     'BUG_CORRECT_TSNBT_OP1_EZERO',\n",
    "\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mb(simu, obs):\n",
    "    return (simu-obs).mean().values.item(0)\n",
    "\n",
    "def rmb(simu, obs):\n",
    "    return ((simu-obs).mean()/np.abs(obs.mean())).values.item(0)*100\n",
    "    \n",
    "def mab(simu, obs):\n",
    "    return (np.abs(simu-obs)).mean().values.item(0)\n",
    "\n",
    "def rmab(simu, obs):\n",
    "    return ((np.abs(simu-obs)).mean()/np.abs(obs.mean())).values.item(0)*100\n",
    "    \n",
    "def rmse(simu, obs):\n",
    "    return np.sqrt(((simu-obs)**2).mean()).values.item(0)\n",
    "\n",
    "def rrmse(simu, obs):\n",
    "    return (np.sqrt(((simu-obs)**2).mean())/np.abs(obs.mean())).values.item(0)*100\n",
    "    \n",
    "def corr(simu, obs):\n",
    "    return xr.corr(simu, obs).values.item(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mb_a(simu, obs):\n",
    "    return (simu-obs).mean()\n",
    "\n",
    "def rmb_a(simu, obs):\n",
    "    return ((simu-obs).mean()/np.abs(obs.mean()))*100\n",
    "    \n",
    "def mab_a(simu, obs):\n",
    "    return (np.abs(simu-obs)).mean()\n",
    "\n",
    "def rmab_a(simu, obs):\n",
    "    return ((np.abs(simu-obs)).mean()/np.abs(obs.mean()))*100\n",
    "    \n",
    "def rmse_a(simu, obs):\n",
    "    return np.sqrt(((simu-obs)**2).mean())\n",
    "\n",
    "def rrmse_a(simu, obs):\n",
    "    return (np.sqrt(((simu-obs)**2).mean())/np.abs(obs.mean()))*100\n",
    "    \n",
    "def corr_a(simu, obs):\n",
    "    r, _ = stats.pearsonr(simu, obs)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can be negative if rmse > std\n",
    "def calculate_score(std_deviation, rmse):\n",
    "    return (std_deviation - rmse) / std_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['Obs'] + [site.name for site in SnowMIP_sites]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_list = []\n",
    "column_indexes = ['mb', 'rmb', 'nmb', 'mab', 'rmab', 'rmse', 'rrmse', 'nrmse', 'r', 'stdd', 'score']\n",
    "\n",
    "for site in SnowMIP_sites+SnowArctic_sites:\n",
    "    row_indexes = [['snd_auto', 'snd_man', 'snw_auto', 'snw_man', 'albs', 'ts', 'tsl', 'tsn', 'SCD'], \n",
    "                   # ['Obs', 'CLASS']+exps]\n",
    "                   ['Obs']+exps]\n",
    "    rows = pd.MultiIndex.from_product(row_indexes)\n",
    "    \n",
    "    df_metrics = pd.DataFrame(index=rows, columns=column_indexes)\n",
    "    df_metrics_list.append(df_metrics)\n",
    "    \n",
    "df_metrics_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, site in enumerate(SnowMIP_sites+SnowArctic_sites):\n",
    "    period = site.period_used\n",
    "    for var in ['snd_auto', 'snd_man', 'snw_auto', 'snw_man', 'albs', 'ts', 'tsl']:\n",
    "\n",
    "        arr1 = ['Obs']+exps\n",
    "        arr2 = [ds_d_Obs_list[i]]+[ds_d_SnowMIP_list[j][i] for j in range(len(exps))]\n",
    "            \n",
    "        for exp, ds_simu in zip(arr1, arr2):\n",
    "\n",
    "            # We are going to make a common mask based on snd_auto so the comparison will be on the same period (auto/man)\n",
    "            mask_obs_snd = ~ds_d_Obs_list[i].snd_auto.where(ds_d_Obs_list[i].snd_auto > 0.1).sel(time=period).isnull()\n",
    "            if exp == 'Obs':\n",
    "                if var == 'snd_auto':\n",
    "                    obs = ds_d_Obs_list[i].snd_auto.where(mask_obs_snd).sel(time=period)\n",
    "                    simu = obs\n",
    "                elif var == 'snd_man':\n",
    "                    if 'snd_man' in list(ds_d_Obs_list[i].keys()):\n",
    "                        mask_obs = ~ds_d_Obs_list[i].snd_man.where(ds_d_Obs_list[i].snd_man > 0.1).sel(time=period).isnull()\n",
    "                        obs = ds_d_Obs_list[i].snd_man.where(mask_obs_snd).where(mask_obs).sel(time=period)\n",
    "                        simu = obs\n",
    "                    else:\n",
    "                        pass\n",
    "                elif var == 'snw_auto':\n",
    "                    if 'snw_auto' in list(ds_d_Obs_list[i].keys()):\n",
    "                        obs = ds_d_Obs_list[i].snw_auto.where(mask_obs_snd).sel(time=period)\n",
    "                        simu = obs\n",
    "                    else:\n",
    "                        pass\n",
    "                elif var == 'snw_man':\n",
    "                    if 'snw_man' in list(ds_d_Obs_list[i].keys()):\n",
    "                        obs = ds_d_Obs_list[i].snw_man.where(mask_obs_snd).sel(time=period)\n",
    "                        simu = obs\n",
    "                    else:\n",
    "                        pass\n",
    "                elif var == 'albs':\n",
    "                    if 'albs' in list(ds_d_Obs_list[i].keys()):\n",
    "                        mask_obs = ~ds_d_Obs_list[i].albs.where(ds_d_Obs_list[i].albs > 0.4)\\\n",
    "                                    .where(ds_d_Obs_list[i].albs < 0.9).sel(time=period).isnull()\n",
    "                        obs = ds_d_Obs_list[i].albs.where(mask_obs_snd).where(mask_obs).sel(time=period)\n",
    "                        simu = obs\n",
    "                    else:\n",
    "                        pass\n",
    "                elif var == 'ts':\n",
    "                    if 'ts' in list(ds_d_Obs_list[i].keys()):\n",
    "                        mask_obs = ~ds_d_Obs_list[i].ts.where(ds_d_Obs_list[i].ts <= 0).sel(time=period).isnull()\n",
    "                        obs = ds_d_Obs_list[i].ts.where(mask_obs_snd).where(mask_obs).sel(time=period)\n",
    "                        simu = obs\n",
    "                    else:\n",
    "                        pass\n",
    "                elif var == 'tsl':\n",
    "                    if 'tsl' in list(ds_d_Obs_list[i].keys()):\n",
    "                        # Get the first soil layer from obs\n",
    "                        if site.name == 'byl':\n",
    "                            obs_sdepth = ds_d_Obs_list[i].tsl.sdepth[1].values.item(0)\n",
    "                        else:\n",
    "                            obs_sdepth = ds_d_Obs_list[i].tsl.sdepth[0].values.item(0) \n",
    "                        obs = ds_d_Obs_list[i].tsl.where(mask_obs_snd).sel(time=period, sdepth=obs_sdepth)\n",
    "                        simu = obs\n",
    "                    else:\n",
    "                        pass\n",
    "                else:\n",
    "                    raise ValueError(var+\" is not supported.\")\n",
    "                    \n",
    "            # Model\n",
    "            else:\n",
    "                mask_simu_snd = ~ds_simu.snd.where(ds_simu.snd > 0.1).sel(time=period).isnull()\n",
    "                if var in ['snd_auto', 'snd_man']:\n",
    "                    simu = ds_simu.snd.where(obs.notnull()).where(mask_simu_snd).sel(time=period)\n",
    "                elif var in ['snw_auto', 'snw_man']:\n",
    "                    simu = ds_simu.snw.where(obs.notnull()).where(mask_simu_snd).sel(time=period)\n",
    "                elif var == 'albs':\n",
    "                    simu = ds_simu['albsn'].where(ds_simu.albsn > 0.4).where(ds_simu.albsn < 0.9).where(obs.notnull())\\\n",
    "                            .where(mask_simu_snd).sel(time=period)\n",
    "                elif var == 'ts':\n",
    "                    simu = ds_simu[var].where(obs.notnull()).where(mask_simu_snd).sel(time=period)-273.15\n",
    "                elif var == 'tsl':\n",
    "                    if 'tsl' in list(ds_d_Obs_list[i].keys()):\n",
    "                        # Interp model on the first soil layer obs\n",
    "                        if obs_sdepth < 0.01: \n",
    "                            ds_d_interp = ds_simu[var]\n",
    "                            model_sdepth = 0.05\n",
    "                        else:\n",
    "                            ds_d_interp = ds_simu[var].interp(layer=ds_d_Obs_list[i].tsl.sdepth.values)\n",
    "                            model_sdepth = obs_sdepth\n",
    "                        simu = ds_d_interp.where(obs.notnull()).where(mask_simu_snd).sel(time=period, layer=model_sdepth)-273.15\n",
    "                    else:\n",
    "                        pass\n",
    "                else:\n",
    "                    raise ValueError(var+\" is not supported.\")\n",
    "\n",
    "            if var in list(ds_d_Obs_list[i].keys()):\n",
    "                # Remove albedo for Arctic sites because suspect wrong values\n",
    "                if not (site.name in ['byl', 'umt', 'umf'] and var == 'albs'):\n",
    "                    df_metrics_list[i].loc[(var, exp), 'mb'] = mb(simu, obs)\n",
    "                    df_metrics_list[i].loc[(var, exp), 'rmb'] = rmb(simu, obs)\n",
    "                    df_metrics_list[i].loc[(var, exp), 'nmb'] = mb(simu, obs)/obs.std().values.item(0)\n",
    "                    df_metrics_list[i].loc[(var, exp), 'mab'] = mab(simu, obs)\n",
    "                    df_metrics_list[i].loc[(var, exp), 'rmab'] = rmab(simu, obs)\n",
    "                    df_metrics_list[i].loc[(var, exp), 'rmse'] = rmse(simu, obs)\n",
    "                    df_metrics_list[i].loc[(var, exp), 'rrmse'] = rrmse(simu, obs)\n",
    "                    df_metrics_list[i].loc[(var, exp), 'nrmse'] = rmse(simu, obs)/obs.std().values.item(0)\n",
    "                    df_metrics_list[i].loc[(var, exp), 'r'] = corr(simu, obs)\n",
    "                    df_metrics_list[i].loc[(var, exp), 'stdd'] = simu.std().values.item(0)\n",
    "                    df_metrics_list[i].loc[(var, exp), 'score'] = calculate_score(obs.std().values.item(0), rmse(simu, obs))\n",
    "\n",
    "            \n",
    "df_metrics_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_list[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, site in enumerate(SnowMIP_sites+SnowArctic_sites):\n",
    "    period = site.period_used\n",
    "    for var in ['SCD']:\n",
    "        \n",
    "        arr1 = ['Obs']+exps\n",
    "        arr2 = [ds_d_Obs_list[i]]+[ds_d_SnowMIP_list[j][i] for j in range(len(exps))]\n",
    "            \n",
    "        for exp, ds_simu in zip(arr1, arr2):\n",
    "\n",
    "            mask = ds_d_Obs_list[i].snd_auto > 0.1\n",
    "            obs = ds_d_Obs_list[i].snd_auto.where(mask).sel(time=period).notnull()\\\n",
    "                    .resample(time='AS-'+calendar.month_abbr[int(period.start[5:7])]).sum()\n",
    "            obs = obs.where(obs > 0)\n",
    "            if exp == 'Obs':\n",
    "                simu = obs\n",
    "            else:\n",
    "                simu = ds_simu.snd.where(ds_simu.snd > 0.1).sel(time=period).notnull()\\\n",
    "                        .resample(time='AS-'+calendar.month_abbr[int(period.start[5:7])]).sum().where(obs.notnull())\n",
    "    \n",
    "            df_metrics_list[i].loc[(var, exp), 'mb'] = mb(simu, obs)\n",
    "            df_metrics_list[i].loc[(var, exp), 'rmb'] = rmb(simu, obs)\n",
    "            df_metrics_list[i].loc[(var, exp), 'nmb'] = mb(simu, obs)/obs.std().values.item(0)\n",
    "            df_metrics_list[i].loc[(var, exp), 'mab'] = mab(simu, obs)\n",
    "            df_metrics_list[i].loc[(var, exp), 'rmab'] = rmab(simu, obs)\n",
    "            df_metrics_list[i].loc[(var, exp), 'rmse'] = rmse(simu, obs)\n",
    "            df_metrics_list[i].loc[(var, exp), 'rrmse'] = rrmse(simu, obs)\n",
    "            df_metrics_list[i].loc[(var, exp), 'nrmse'] = rmse(simu, obs)/obs.std().values.item(0)\n",
    "            df_metrics_list[i].loc[(var, exp), 'r'] = corr(simu, obs)\n",
    "            df_metrics_list[i].loc[(var, exp), 'stdd'] = simu.std().values.item(0)\n",
    "            df_metrics_list[i].loc[(var, exp), 'score'] = calculate_score(obs.std().values.item(0), rmse(simu, obs))\n",
    "            \n",
    "df_metrics_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_list[-2].loc[('albs')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Menard plot\n",
    "https://journals.ametsoc.org/view/journals/bams/102/1/BAMS-D-19-0329.1.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For calculating the mean of each site\n",
    "df_gather = df_metrics_list[0].copy()\n",
    "for var in ['snd_auto', 'snd_man', 'snw_auto', 'snw_man', 'albs', 'ts', 'tsl', 'tsn', 'SCD']:\n",
    "    for metric in ['mb', 'rmb', 'nmb', 'mab', 'rmab', 'rmse', 'rrmse', 'nrmse', 'r', 'stdd', 'score']:\n",
    "        # for exp in ['Obs', 'CLASS']+exps:\n",
    "        for exp in ['Obs']+exps:\n",
    "            array_gather = np.array([df_metrics_list[i].loc[(var, exp), metric] for i, site in enumerate(SnowMIP_sites)])\n",
    "            df_gather.loc[(var, exp), metric] = array_gather\n",
    "\n",
    "df_gather_Arctic = df_metrics_list[0].copy()\n",
    "for var in ['snd_auto', 'snd_man', 'snw_auto', 'snw_man', 'albs', 'ts', 'tsl', 'tsn', 'SCD']:\n",
    "    for metric in ['mb', 'rmb', 'nmb', 'mab', 'rmab', 'rmse', 'rrmse', 'nrmse', 'r', 'stdd', 'score']:\n",
    "        # for exp in ['Obs', 'CLASS']+exps:\n",
    "        for exp in ['Obs']+exps:\n",
    "            if exp == 'CLASS':\n",
    "                array_gather = np.nan\n",
    "            else:\n",
    "                array_gather = np.array([df_metrics_list[i].loc[(var, exp), metric] for i, site in enumerate(SnowMIP_sites+SnowArctic_sites)])\n",
    "            df_gather_Arctic.loc[(var, exp), metric] = array_gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gather.loc[('albs')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gather_Arctic.loc[('albs')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = pplt.subplots(ncols=4, nrows=4, sharey=0, refaspect=0.8, refwidth=1.3)\n",
    "\n",
    "colors = pplt.constructor.Cycle('default').by_key()['color']+pplt.constructor.Cycle('Accent').by_key()['color']\n",
    "xrotation = 60\n",
    "markers = ['x']*len(SnowMIP_sites) + ['^']*len(SnowArctic_sites)\n",
    "marker_mean='.'; label_mean='mean (SnowMIP)'; color_mean='k'; marker_mean_size=80\n",
    "marker_mean_arc='.'; label_mean_arc='mean (SnowMIP + Arctic)'; color_mean_arc='red9'; marker_mean_arc_size=80\n",
    "\n",
    "# Snow depth\n",
    "h_list = []\n",
    "for i, site in enumerate(SnowMIP_sites+SnowArctic_sites):\n",
    "    h = axs[0].scatter(df_metrics_list[i].loc[('snd_auto')].rmse[1:]*100, marker=markers[i], label=site.name, color=colors[i])\n",
    "    h_list.append(h)\n",
    "h_mean = axs[0].scatter(df_gather.loc[('snd_auto')].rmse[1:].apply(np.mean)*100, \n",
    "                        marker=marker_mean, label=label_mean, color=color_mean, markersize=marker_mean_size)\n",
    "h_mean_arc = axs[0].scatter(df_gather_Arctic.loc[('snd_auto')].rmse[1:].apply(np.mean)*100, \n",
    "                        marker=marker_mean_arc, label=label_mean_arc, color=color_mean_arc, markersize=marker_mean_arc_size)\n",
    "axs[0].format(title='Snow depth (auto)', ylabel='RMSE [cm]', xrotation=xrotation, ylim=(0, 85))\n",
    "\n",
    "for i, site in enumerate(SnowMIP_sites+SnowArctic_sites):\n",
    "    axs[2].scatter(df_metrics_list[i].loc[('snd_man')].rmse[1:]*100, marker=markers[i], label=site.name, color=colors[i])\n",
    "axs[2].scatter(df_gather.loc[('snd_man')].rmse[1:].apply(np.mean)*100, \n",
    "               marker=marker_mean, label=label_mean, color=color_mean, markersize=marker_mean_size)\n",
    "# axs[2].scatter(df_gather_Arctic.loc[('snd_man')].rmse[1:].apply(np.nanmean)*100, \n",
    "#                 marker=marker_mean_arc, label=label_mean_arc, color=color_mean_arc, markersize=marker_mean_arc_size)\n",
    "axs[2].format(title='Snow depth (man)', ylabel='RMSE [cm]', xrotation=xrotation, ylim=(0, 85))\n",
    "\n",
    "for i, site in enumerate(SnowMIP_sites+SnowArctic_sites):\n",
    "    axs[1].scatter(df_metrics_list[i].loc[('snd_auto')].rmse[1:]/df_metrics_list[i].loc[('snd_auto')].stdd[1:], \n",
    "                   marker=markers[i], label=site.name, color=colors[i])\n",
    "axs[1].scatter(df_gather.loc[('snd_auto')].nrmse[1:].apply(np.mean), \n",
    "               marker=marker_mean, label=label_mean, color=color_mean, markersize=marker_mean_size)\n",
    "axs[1].scatter(df_gather_Arctic.loc[('snd_auto')].nrmse[1:].apply(np.mean), \n",
    "                marker=marker_mean_arc, label=label_mean_arc, color=color_mean_arc, markersize=marker_mean_arc_size)\n",
    "# axs[1].format(title='Snow depth (auto)', ylabel='NRMSE', xrotation=xrotation, ylim=(0, 1.58))\n",
    "axs[1].format(title='Snow depth (auto)', ylabel='NRMSE', xrotation=xrotation, ylim=(0, 2.77))\n",
    "\n",
    "for i, site in enumerate(SnowMIP_sites+SnowArctic_sites):\n",
    "    axs[3].scatter(df_metrics_list[i].loc[('snd_man')].rmse[1:]/df_metrics_list[i].loc[('snd_man')].stdd[1:], \n",
    "                   marker=markers[i], label=site.name, color=colors[i])\n",
    "axs[3].scatter(df_gather.loc[('snd_man')].nrmse[1:].apply(np.mean), \n",
    "               marker=marker_mean, label=label_mean, color=color_mean, markersize=marker_mean_size)\n",
    "# axs[3].scatter(df_gather_Arctic.loc[('snd_man')].nrmse[1:].apply(np.nanmean), \n",
    "#                 marker=marker_mean_arc, label=label_mean_arc, color=color_mean_arc, markersize=marker_mean_arc_size)\n",
    "axs[3].format(title='Snow depth (man)', ylabel='NRMSE', xrotation=xrotation, ylim=(0, 2.77))\n",
    "\n",
    "\n",
    "# Snow Water Equivalent\n",
    "h_list = []\n",
    "for i, site in enumerate(SnowMIP_sites+SnowArctic_sites):\n",
    "    h = axs[4].scatter(df_metrics_list[i].loc[('snw_auto')].rmse[1:], marker=markers[i], label=site.name, color=colors[i])\n",
    "    h_list.append(h)\n",
    "h_mean = axs[4].scatter(df_gather.loc[('snw_auto')].rmse[1:].apply(np.nanmean), \n",
    "                        marker=marker_mean, label=label_mean, color=color_mean, markersize=marker_mean_size)\n",
    "# axs[4].scatter(df_gather_Arctic.loc[('snw_auto')].rmse[1:].apply(np.nanmean), \n",
    "#                 marker=marker_mean_arc, label=label_mean_arc, color=color_mean_arc, markersize=marker_mean_arc_size)\n",
    "axs[4].format(title='SWE (auto)', ylabel='RMSE [mm]', xrotation=xrotation, ylim=(0, 270))\n",
    "\n",
    "for i, site in enumerate(SnowMIP_sites+SnowArctic_sites):\n",
    "    axs[6].scatter(df_metrics_list[i].loc[('snw_man')].rmse[1:], marker=markers[i], label=site.name, color=colors[i])\n",
    "axs[6].scatter(df_gather.loc[('snw_man')].rmse[1:].apply(np.nanmean), \n",
    "               marker=marker_mean, label=label_mean, color=color_mean, markersize=marker_mean_size)\n",
    "# axs[6].scatter(df_gather_Arctic.loc[('snw_man')].rmse[1:].apply(np.nanmean), \n",
    "#                 marker=marker_mean_arc, label=label_mean_arc, color=color_mean_arc, markersize=marker_mean_arc_size)\n",
    "axs[6].format(title='SWE (man)', ylabel='RMSE [mm]', xrotation=xrotation, ylim=(0, 270))\n",
    "\n",
    "for i, site in enumerate(SnowMIP_sites+SnowArctic_sites):\n",
    "    axs[5].scatter(df_metrics_list[i].loc[('snw_auto')].rmse[1:]/df_metrics_list[i].loc[('snw_auto')].stdd[1:], \n",
    "                   marker=markers[i], label=site.name, color=colors[i])\n",
    "axs[5].scatter(df_gather.loc[('snw_auto')].nrmse[1:].apply(np.nanmean), \n",
    "               marker=marker_mean, label=label_mean, color=color_mean, markersize=marker_mean_size)\n",
    "# axs[5].scatter(df_gather_Arctic.loc[('snw_auto')].nrmse[1:].apply(np.nanmean), \n",
    "#                 marker=marker_mean_arc, label=label_mean_arc, color=color_mean_arc, markersize=marker_mean_arc_size)\n",
    "axs[5].format(title='SWE (auto)', ylabel='NRMSE', xrotation=xrotation, ylim=(0, 1.65))\n",
    "\n",
    "for i, site in enumerate(SnowMIP_sites+SnowArctic_sites):\n",
    "    axs[7].scatter(df_metrics_list[i].loc[('snw_man')].rmse[1:]/df_metrics_list[i].loc[('snw_man')].stdd[1:], \n",
    "                   marker=markers[i], label=site.name, color=colors[i])\n",
    "axs[7].scatter(df_gather.loc[('snw_man')].nrmse[1:].apply(np.nanmean), \n",
    "               marker=marker_mean, label=label_mean, color=color_mean, markersize=marker_mean_size)\n",
    "# axs[7].scatter(df_gather_Arctic.loc[('snw_man')].nrmse[1:].apply(np.nanmean), \n",
    "#                 marker=marker_mean_arc, label=label_mean_arc, color=color_mean_arc, markersize=marker_mean_arc_size)\n",
    "axs[7].format(title='SWE (man)', ylabel='NRMSE', xrotation=xrotation, ylim=(0, 1.65))\n",
    "\n",
    "\n",
    "# Albedo\n",
    "h_list = []\n",
    "for i, site in enumerate(SnowMIP_sites+SnowArctic_sites):\n",
    "    h = axs[8].scatter(df_metrics_list[i].loc[('albs')].rmse[1:], marker=markers[i], label=site.name, color=colors[i])\n",
    "    h_list.append(h)\n",
    "h_mean = axs[8].scatter(df_gather.loc[('albs')].rmse[1:].apply(np.nanmean), \n",
    "                        marker=marker_mean, label=label_mean, color=color_mean, markersize=marker_mean_size)\n",
    "# axs[8].scatter(df_gather_Arctic.loc[('albs')].rmse[1:].apply(np.nanmean), \n",
    "#                 marker=marker_mean_arc, label=label_mean_arc, color=color_mean_arc, markersize=marker_mean_arc_size)\n",
    "axs[8].format(title='Albedo', ylabel='RMSE [-]', xrotation=xrotation, ylim=(0, 0.1))\n",
    "\n",
    "h_list = []\n",
    "for i, site in enumerate(SnowMIP_sites+SnowArctic_sites):\n",
    "    h = axs[9].scatter(df_metrics_list[i].loc[('albs')].nrmse[1:], marker=markers[i], label=site.name, color=colors[i])\n",
    "    h_list.append(h)\n",
    "h_mean = axs[9].scatter(df_gather.loc[('albs')].nrmse[1:].apply(np.nanmean), \n",
    "                        marker=marker_mean, label=label_mean, color=color_mean, markersize=marker_mean_size)\n",
    "# axs[9].scatter(df_gather_Arctic.loc[('albs')].nrmse[1:].apply(np.nanmean), \n",
    "#                 marker=marker_mean_arc, label=label_mean_arc, color=color_mean_arc, markersize=marker_mean_arc_size)\n",
    "axs[9].format(title='Albedo', ylabel='NRMSE', xrotation=xrotation, ylim=(0, 1.05))\n",
    "\n",
    "# Surface temperature\n",
    "h_list = []\n",
    "for i, site in enumerate(SnowMIP_sites+SnowArctic_sites):\n",
    "    h = axs[10].scatter(df_metrics_list[i].loc[('ts')].rmse[1:], marker=markers[i], label=site.name, color=colors[i])\n",
    "    h_list.append(h)\n",
    "h_mean = axs[10].scatter(df_gather.loc[('ts')].rmse[1:].apply(np.nanmean), \n",
    "                        marker=marker_mean, label=label_mean, color=color_mean, markersize=marker_mean_size)\n",
    "axs[10].scatter(df_gather_Arctic.loc[('ts')].rmse[1:].apply(np.nanmean), \n",
    "                marker=marker_mean_arc, label=label_mean_arc, color=color_mean_arc, markersize=marker_mean_arc_size)\n",
    "axs[10].format(title='Surface temperature', ylabel='RMSE [°C]', xrotation=xrotation, ylim=(0, None))\n",
    "\n",
    "h_list = []\n",
    "for i, site in enumerate(SnowMIP_sites+SnowArctic_sites):\n",
    "    h = axs[11].scatter(df_metrics_list[i].loc[('ts')].nrmse[1:], marker=markers[i], label=site.name, color=colors[i])\n",
    "    h_list.append(h)\n",
    "h_mean = axs[11].scatter(df_gather.loc[('ts')].nrmse[1:].apply(np.nanmean), \n",
    "                        marker=marker_mean, label=label_mean, color=color_mean, markersize=marker_mean_size)\n",
    "axs[11].scatter(df_gather_Arctic.loc[('ts')].nrmse[1:].apply(np.nanmean), \n",
    "                marker=marker_mean_arc, label=label_mean_arc, color=color_mean_arc, markersize=marker_mean_arc_size)\n",
    "axs[11].format(title='Surface temperature', ylabel='NRMSE', xrotation=xrotation, ylim=(0, None))\n",
    "\n",
    "# Soil temperature\n",
    "h_list = []\n",
    "for i, site in enumerate(SnowMIP_sites+SnowArctic_sites):\n",
    "    h = axs[12].scatter(df_metrics_list[i].loc[('tsl')].rmse[1:], marker=markers[i], label=site.name, color=colors[i])\n",
    "    h_list.append(h)\n",
    "h_mean = axs[12].scatter(df_gather.loc[('tsl')].rmse[1:].apply(np.nanmean), \n",
    "                        marker=marker_mean, label=label_mean, color=color_mean, markersize=marker_mean_size)\n",
    "axs[12].scatter(df_gather_Arctic.loc[('tsl')].rmse[1:].apply(np.nanmean), \n",
    "                marker=marker_mean_arc, label=label_mean_arc, color=color_mean_arc, markersize=marker_mean_arc_size)\n",
    "axs[12].format(title='Soil temperature', ylabel='RMSE [°C]', xrotation=xrotation, ylim=(0, None))\n",
    "\n",
    "h_list = []\n",
    "for i, site in enumerate(SnowMIP_sites+SnowArctic_sites):\n",
    "    h = axs[13].scatter(df_metrics_list[i].loc[('tsl')].nrmse[1:], marker=markers[i], label=site.name, color=colors[i])\n",
    "    h_list.append(h)\n",
    "h_mean = axs[13].scatter(df_gather.loc[('tsl')].nrmse[1:].apply(np.nanmean), \n",
    "                        marker=marker_mean, label=label_mean, color=color_mean, markersize=marker_mean_size)\n",
    "axs[13].scatter(df_gather_Arctic.loc[('tsl')].nrmse[1:].apply(np.nanmean), \n",
    "                marker=marker_mean_arc, label=label_mean_arc, color=color_mean_arc, markersize=marker_mean_arc_size)\n",
    "axs[13].format(title='Soil temperature', ylabel='NRMSE', xrotation=xrotation, ylim=(0, None))\n",
    "\n",
    "# SCD\n",
    "h_list = []\n",
    "for i, site in enumerate(SnowMIP_sites+SnowArctic_sites):\n",
    "    h = axs[14].scatter(df_metrics_list[i].loc[('SCD')].rmse[1:], marker=markers[i], label=site.name, color=colors[i])\n",
    "    h_list.append(h)\n",
    "h_mean = axs[14].scatter(df_gather.loc[('SCD')].rmse[1:].apply(np.nanmean), \n",
    "                        marker=marker_mean, label=label_mean, color=color_mean, markersize=marker_mean_size)\n",
    "axs[14].scatter(df_gather_Arctic.loc[('SCD')].rmse[1:].apply(np.nanmean), \n",
    "                marker=marker_mean_arc, label=label_mean_arc, color=color_mean_arc, markersize=marker_mean_arc_size)\n",
    "axs[14].format(title='SCD', ylabel='RMSE [d]', xrotation=xrotation, ylim=(0, None))\n",
    "\n",
    "h_list = []\n",
    "for i, site in enumerate(SnowMIP_sites+SnowArctic_sites):\n",
    "    h = axs[15].scatter(df_metrics_list[i].loc[('SCD')].nrmse[1:], marker=markers[i], label=site.name, color=colors[i])\n",
    "    h_list.append(h)\n",
    "h_mean = axs[15].scatter(df_gather.loc[('SCD')].nrmse[1:].apply(np.nanmean), \n",
    "                        marker=marker_mean, label=label_mean, color=color_mean, markersize=marker_mean_size)\n",
    "axs[15].scatter(df_gather_Arctic.loc[('SCD')].nrmse[1:].apply(np.nanmean), \n",
    "                marker=marker_mean_arc, label=label_mean_arc, color=color_mean_arc, markersize=marker_mean_arc_size)\n",
    "axs[15].format(title='SCD', ylabel='NRMSE', xrotation=xrotation, ylim=(0, None))\n",
    "\n",
    "x_min = -0.7\n",
    "# x_max = 2.7\n",
    "x_max = 5.7\n",
    "for i, ax in enumerate(axs):\n",
    "    # ax.format(xticklabels=['CLASS']+[exp[:-10] for exp in exps], xlim=(x_min, x_max))\n",
    "    ax.format(xticklabels=[exp[:-10] for exp in exps], xlim=(x_min, x_max))\n",
    "    if (i % 2) != 0:\n",
    "        ax.hlines(1, x_min, x_max, color='k', lw=1, alpha=0.2, zorder=0, ls='--')\n",
    "\n",
    "# Snow Depth uncertainty\n",
    "axs[0].hlines(10, x_min, x_max, color='k', lw=1, alpha=0.2, zorder=0, ls='--')\n",
    "axs[2].hlines(10, x_min, x_max, color='k', lw=1, alpha=0.2, zorder=0, ls='--')\n",
    "\n",
    "# SWE uncertainty\n",
    "axs[4].hlines(25, x_min, x_max, color='k', lw=1, alpha=0.2, zorder=0, ls='--')\n",
    "axs[6].hlines(25, x_min, x_max, color='k', lw=1, alpha=0.2, zorder=0, ls='--')\n",
    "\n",
    "# Soil temp uncertainty\n",
    "axs[12].hlines(0.4, x_min, x_max, color='k', lw=1, alpha=0.2, zorder=0, ls='--')\n",
    "\n",
    "    \n",
    "fig.legend(h_list+[h_mean, h_mean_arc], loc='t', ncols=len(SnowMIP_sites)+len(SnowArctic_sites), center=True, frame=False)\n",
    "fig.format(abc='(a)', abcloc='ul')\n",
    "# fig.save('img/tn1_rmse.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_array = []\n",
    "for var in ['snd_auto', 'snd_man', 'snw_auto', 'snw_man', 'albs', 'ts', 'tsl', 'SCD']:\n",
    "    score_array.append(df_gather.loc[(var)].nrmse[1:].apply(np.nanmean).values)\n",
    "score_array = np.array(score_array).mean(axis=0)\n",
    "score_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_array = []\n",
    "for var in ['snd_auto', 'snd_man', 'snw_auto', 'snw_man', 'albs', 'ts', 'tsl', 'SCD']:\n",
    "    score_array.append(df_gather_Arctic.loc[(var)].nrmse[1:].apply(np.nanmean).values)\n",
    "score_array = np.array(score_array).mean(axis=0)\n",
    "score_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score (no weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No weight (I guess not good because raising the score because of lesser stations for SWE_auto\n",
    "# -> raising artificially the score\n",
    "score_array = []\n",
    "for var in ['snd_auto', 'snd_man', 'snw_auto', 'snw_man', 'albs', 'ts', 'tsl', 'SCD']:\n",
    "    score_array.append(df_gather.loc[(var)].score[1:].apply(np.nanmean).values)\n",
    "score_array = np.array(score_array).mean(axis=0)\n",
    "score_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No weight (I guess not good because raising the score because of lesser stations for SWE_auto\n",
    "# -> raising artificially the score\n",
    "score_array = []\n",
    "for var in ['snd_auto', 'snd_man', 'snw_auto', 'snw_man', 'albs', 'ts', 'tsl', 'SCD']:\n",
    "    score_array.append(df_gather_Arctic.loc[(var)].score[1:].apply(np.nanmean).values)\n",
    "score_array = np.array(score_array).mean(axis=0)\n",
    "score_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score (weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best score?\n",
    "score_array = []\n",
    "weights = []\n",
    "for var in ['snd_auto', 'snd_man', 'snw_auto', 'snw_man', 'albs', 'ts', 'tsl', 'SCD']:\n",
    "    score_array.append(df_gather.loc[(var)].score[1:].apply(np.nanmean).values)\n",
    "    # Weight per obs sites (give twice more weight to sn from auto/man)\n",
    "    # Make sense because other variable have smaller std and so higher NRMSE\n",
    "    # (which might give them too much importance)\n",
    "    # weight = np.nansum(df_gather.loc[(var)].score[1:]['Ref_30min_ext']*0+1)\n",
    "    weight = np.nansum(df_gather.loc[(var)].score[1:]['DEF']*0+1)\n",
    "    # if var in ['snd_auto', 'snd_man', 'snw_auto', 'snw_man']:\n",
    "    #     weight = weight*0.5\n",
    "    weights.append(weight)\n",
    "score_array = np.average(np.array(score_array), axis=0, weights=weights)\n",
    "score_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best score?\n",
    "score_array = []\n",
    "weights = []\n",
    "for var in ['snd_auto', 'snd_man', 'snw_auto', 'snw_man', 'albs', 'ts', 'tsl', 'SCD']:\n",
    "    score_array.append(df_gather_Arctic.loc[(var)].score[1:].apply(np.nanmean).values)\n",
    "    # Weight per obs sites (give twice more weight to sn from auto/man)\n",
    "    # Make sense because other variable have smaller std and so higher NRMSE\n",
    "    # (which might give them too much importance)\n",
    "    # weight = np.nansum(df_gather_Arctic.loc[(var)].score[1:]['Ref_30min_ext']*0+1)\n",
    "    weight = np.nansum(df_gather_Arctic.loc[(var)].score[1:]['DEF']*0+1)\n",
    "    # if var in ['snd_auto', 'snd_man', 'snw_auto', 'snw_man']:\n",
    "    #     weight = weight*0.5\n",
    "    weights.append(weight)\n",
    "score_array = np.average(np.array(score_array), axis=0, weights=weights)\n",
    "score_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Best score?\n",
    "# score_array = []\n",
    "# weights = []\n",
    "# for var in ['snd_auto', 'snd_man', 'snw_auto', 'snw_man', 'albs', 'ts', 'tsl', 'SCD']:\n",
    "#     score_array.append(df_gather_Arctic.loc[(var)].score[1:].apply(np.nanmean).values)\n",
    "#     # Weight per obs sites (give twice more weight to sn from auto/man)\n",
    "#     # Make sense because other variable have smaller std and so higher NRMSE\n",
    "#     # (which might give them too much importance)\n",
    "#     weight = np.nansum(df_gather_Arctic.loc[(var)].score[1:]['Ref_30min_ext']*0+1)\n",
    "#     # if var in ['snd_auto', 'snd_man', 'snw_auto', 'snw_man']:\n",
    "#     #     weight = weight*0.5\n",
    "#     weights.append(weight)\n",
    "# score_array = np.average(np.array(score_array), axis=0, weights=weights)\n",
    "# score_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative score\n",
    "score_array = []\n",
    "weights = []\n",
    "for var in ['snd_auto', 'snd_man', 'snw_auto', 'snw_man', 'albs', 'ts', 'tsl', 'SCD']:\n",
    "    score_array.append(df_gather.loc[(var)].score[1:].apply(np.nanmean).values)\n",
    "    # Weight per obs sites and 0.5 for sn auto/man\n",
    "    weight = np.nansum(df_gather.loc[(var)].score[1:]['DEF']*0+1)\n",
    "    if var in ['snd_auto', 'snd_man', 'snw_auto', 'snw_man']:\n",
    "        weight = weight*0.5\n",
    "    weights.append(weight)\n",
    "score_array = np.average(np.array(score_array), axis=0, weights=weights)\n",
    "score_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative score\n",
    "score_array = []\n",
    "weights = []\n",
    "for var in ['snd_auto', 'snd_man', 'snw_auto', 'snw_man', 'albs', 'ts', 'tsl', 'SCD']:\n",
    "    score_array.append(df_gather_Arctic.loc[(var)].score[1:].apply(np.nanmean).values)\n",
    "    # Weight per obs sites and 0.5 for sn auto/man\n",
    "    weight = np.nansum(df_gather_Arctic.loc[(var)].score[1:]['DEF']*0+1)\n",
    "    if var in ['snd_auto', 'snd_man', 'snw_auto', 'snw_man']:\n",
    "        weight = weight*0.5\n",
    "    weights.append(weight)\n",
    "score_array = np.average(np.array(score_array), axis=0, weights=weights)\n",
    "score_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = pplt.subplots(ncols=4, nrows=4, sharey=0, refaspect=0.8, refwidth=1.3)\n",
    "\n",
    "colors = pplt.constructor.Cycle('default').by_key()['color']+pplt.constructor.Cycle('Accent').by_key()['color']\n",
    "xrotation=60\n",
    "markers = ['x']*len(SnowMIP_sites) + ['^']*len(SnowArctic_sites)\n",
    "marker_mean='.'; label_mean='mean'; color_mean='k'; marker_mean_size=80\n",
    "marker_mean_arc='.'; label_mean_arc='mean (SnowMIP + Arctic)'; color_mean_arc='red9'; marker_mean_arc_size=80\n",
    "\n",
    "# Snow depth\n",
    "h_list = []\n",
    "for i, site in enumerate(SnowMIP_sites+SnowArctic_sites):\n",
    "    h = axs[0].scatter(df_metrics_list[i].loc[('snd_auto')].mb[1:]*100, marker=markers[i], label=site.name, color=colors[i])\n",
    "    h_list.append(h)\n",
    "h_mean = axs[0].scatter(df_gather.loc[('snd_auto')].mb[1:].apply(np.mean)*100, \n",
    "                        marker=marker_mean, label=label_mean, color=color_mean, markersize=marker_mean_size)\n",
    "h_mean_arc = axs[0].scatter(df_gather_Arctic.loc[('snd_auto')].mb[1:].apply(np.mean)*100, \n",
    "                        marker=marker_mean_arc, label=label_mean_arc, color=color_mean_arc, markersize=marker_mean_arc_size)\n",
    "axs[0].format(title='Snow depth (auto)', ylabel='Mean bias [cm]', xrotation=xrotation, ylim=(-75, 50))\n",
    "\n",
    "for i, site in enumerate(SnowMIP_sites+SnowArctic_sites):\n",
    "    axs[2].scatter(df_metrics_list[i].loc[('snd_man')].mb[1:]*100, marker=markers[i], label=site.name, color=colors[i])\n",
    "axs[2].scatter(df_gather.loc[('snd_man')].mb[1:].apply(np.mean)*100, \n",
    "               marker=marker_mean, label=label_mean, color=color_mean, markersize=marker_mean_size)\n",
    "# axs[2].scatter(df_gather_Arctic.loc[('snd_man')].mb[1:].apply(np.nanmean)*100, \n",
    "#                 marker=marker_mean_arc, label=label_mean_arc, color=color_mean_arc, markersize=marker_mean_arc_size)\n",
    "axs[2].format(title='Snow depth (man)', ylabel='Mean bias [cm]', xrotation=xrotation, ylim=(-75, 50))\n",
    "\n",
    "for i, site in enumerate(SnowMIP_sites+SnowArctic_sites):\n",
    "    axs[1].scatter(df_metrics_list[i].loc[('snd_auto')].mb[1:]/df_metrics_list[i].loc[('snd_auto')].stdd[1:], \n",
    "                   marker=markers[i], label=site.name, color=colors[i])\n",
    "axs[1].scatter(df_gather.loc[('snd_auto')].nmb[1:].apply(np.mean), \n",
    "               marker=marker_mean, label=label_mean, color=color_mean, markersize=marker_mean_size)\n",
    "axs[1].scatter(df_gather_Arctic.loc[('snd_auto')].nmb[1:].apply(np.mean), \n",
    "                marker=marker_mean_arc, label=label_mean_arc, color=color_mean_arc, markersize=marker_mean_arc_size)\n",
    "axs[1].format(title='Snow depth (auto)', ylabel='Normalized bias', xrotation=xrotation, ylim=(-2.5, 1.2))\n",
    "\n",
    "for i, site in enumerate(SnowMIP_sites+SnowArctic_sites):\n",
    "    axs[3].scatter(df_metrics_list[i].loc[('snd_man')].mb[1:]/df_metrics_list[i].loc[('snd_man')].stdd[1:], \n",
    "                   marker=markers[i], label=site.name, color=colors[i])\n",
    "axs[3].scatter(df_gather.loc[('snd_man')].nmb[1:].apply(np.mean), \n",
    "               marker=marker_mean, label=label_mean, color=color_mean, markersize=marker_mean_size)\n",
    "# axs[3].scatter(df_gather_Arctic.loc[('snd_man')].nmb[1:].apply(np.nanmean), \n",
    "#                 marker=marker_mean_arc, label=label_mean_arc, color=color_mean_arc, markersize=marker_mean_arc_size)\n",
    "axs[3].format(title='Snow depth (man)', ylabel='Normalized bias', xrotation=xrotation, ylim=(-2.5, 1.2))\n",
    "\n",
    "\n",
    "# Snow Water Equivalent\n",
    "h_list = []\n",
    "for i, site in enumerate(SnowMIP_sites+SnowArctic_sites):\n",
    "    h = axs[4].scatter(df_metrics_list[i].loc[('snw_auto')].mb[1:], marker=markers[i], label=site.name, color=colors[i])\n",
    "    h_list.append(h)\n",
    "h_mean = axs[4].scatter(df_gather.loc[('snw_auto')].mb[1:].apply(np.nanmean), \n",
    "                        marker=marker_mean, label=label_mean, color=color_mean, markersize=marker_mean_size)\n",
    "# axs[4].scatter(df_gather_Arctic.loc[('snw_auto')].mb[1:].apply(np.nanmean), \n",
    "#                 marker=marker_mean_arc, label=label_mean_arc, color=color_mean_arc, markersize=marker_mean_arc_size)\n",
    "axs[4].format(title='SWE (auto)', ylabel='Mean bias [mm]', xrotation=xrotation, ylim=(-235, 100))\n",
    "\n",
    "for i, site in enumerate(SnowMIP_sites+SnowArctic_sites):\n",
    "    axs[6].scatter(df_metrics_list[i].loc[('snw_man')].mb[1:], marker=markers[i], label=site.name, color=colors[i])\n",
    "axs[6].scatter(df_gather.loc[('snw_man')].mb[1:].apply(np.nanmean), \n",
    "               marker=marker_mean, label=label_mean, color=color_mean, markersize=marker_mean_size)\n",
    "# axs[6].scatter(df_gather_Arctic.loc[('snw_man')].mb[1:].apply(np.nanmean), \n",
    "#                 marker=marker_mean_arc, label=label_mean_arc, color=color_mean_arc, markersize=marker_mean_arc_size)\n",
    "axs[6].format(title='SWE (man)', ylabel='Mean bias [mm]', xrotation=xrotation, ylim=(-235, 100))\n",
    "\n",
    "for i, site in enumerate(SnowMIP_sites+SnowArctic_sites):\n",
    "    axs[5].scatter(df_metrics_list[i].loc[('snw_auto')].mb[1:]/df_metrics_list[i].loc[('snw_auto')].stdd[1:], \n",
    "                   marker=markers[i], label=site.name, color=colors[i])\n",
    "axs[5].scatter(df_gather.loc[('snw_auto')].nmb[1:].apply(np.nanmean), \n",
    "               marker=marker_mean, label=label_mean, color=color_mean, markersize=marker_mean_size)\n",
    "# axs[5].scatter(df_gather_Arctic.loc[('snw_auto')].nmb[1:].apply(np.nanmean), \n",
    "#                 marker=marker_mean_arc, label=label_mean_arc, color=color_mean_arc, markersize=marker_mean_arc_size)\n",
    "axs[5].format(title='SWE (auto)', ylabel='Normalized bias', xrotation=xrotation, ylim=(-1.5, 0.53))\n",
    "\n",
    "for i, site in enumerate(SnowMIP_sites+SnowArctic_sites):\n",
    "    axs[7].scatter(df_metrics_list[i].loc[('snw_man')].mb[1:]/df_metrics_list[i].loc[('snw_man')].stdd[1:], \n",
    "                   marker=markers[i], label=site.name, color=colors[i])\n",
    "axs[7].scatter(df_gather.loc[('snw_man')].nmb[1:].apply(np.nanmean), \n",
    "               marker=marker_mean, label=label_mean, color=color_mean, markersize=marker_mean_size)\n",
    "# axs[7].scatter(df_gather_Arctic.loc[('snw_man')].nmb[1:].apply(np.nanmean), \n",
    "#                 marker=marker_mean_arc, label=label_mean_arc, color=color_mean_arc, markersize=marker_mean_arc_size)\n",
    "axs[7].format(title='SWE (man)', ylabel='Normalized bias', xrotation=xrotation, ylim=(-1.5, 0.53))\n",
    "\n",
    "\n",
    "# Albedo\n",
    "h_list = []\n",
    "for i, site in enumerate(SnowMIP_sites+SnowArctic_sites):\n",
    "    h = axs[8].scatter(df_metrics_list[i].loc[('albs')].mb[1:], marker=markers[i], label=site.name, color=colors[i])\n",
    "    h_list.append(h)\n",
    "h_mean = axs[8].scatter(df_gather.loc[('albs')].mb[1:].apply(np.nanmean), \n",
    "                        marker=marker_mean, label=label_mean, color=color_mean, markersize=marker_mean_size)\n",
    "# axs[8].scatter(df_gather_Arctic.loc[('albs')].mb[1:].apply(np.nanmean), \n",
    "#                 marker=marker_mean_arc, label=label_mean_arc, color=color_mean_arc, markersize=marker_mean_arc_size)\n",
    "axs[8].format(title='Albedo', ylabel='Mean bias [-]', xrotation=xrotation, ylim=(None, None))\n",
    "\n",
    "h_list = []\n",
    "for i, site in enumerate(SnowMIP_sites+SnowArctic_sites):\n",
    "    h = axs[9].scatter(df_metrics_list[i].loc[('albs')].nmb[1:], marker=markers[i], label=site.name, color=colors[i])\n",
    "    h_list.append(h)\n",
    "h_mean = axs[9].scatter(df_gather.loc[('albs')].nmb[1:].apply(np.nanmean), \n",
    "                        marker=marker_mean, label=label_mean, color=color_mean, markersize=marker_mean_size)\n",
    "# axs[9].scatter(df_gather_Arctic.loc[('albs')].nmb[1:].apply(np.nanmean), \n",
    "#                 marker=marker_mean_arc, label=label_mean_arc, color=color_mean_arc, markersize=marker_mean_arc_size)\n",
    "axs[9].format(title='Albedo', ylabel='Normalized bias', xrotation=xrotation, ylim=(None, None))\n",
    "\n",
    "# Surface temperature\n",
    "h_list = []\n",
    "for i, site in enumerate(SnowMIP_sites+SnowArctic_sites):\n",
    "    h = axs[10].scatter(df_metrics_list[i].loc[('ts')].mb[1:], marker=markers[i], label=site.name, color=colors[i])\n",
    "    h_list.append(h)\n",
    "h_mean = axs[10].scatter(df_gather.loc[('ts')].mb[1:].apply(np.nanmean), \n",
    "                        marker=marker_mean, label=label_mean, color=color_mean, markersize=marker_mean_size)\n",
    "axs[10].scatter(df_gather_Arctic.loc[('ts')].mb[1:].apply(np.nanmean), \n",
    "                marker=marker_mean_arc, label=label_mean_arc, color=color_mean_arc, markersize=marker_mean_arc_size)\n",
    "axs[10].format(title='Surface temperature', ylabel='Mean bias [°C]', xrotation=xrotation, ylim=(None, None))\n",
    "\n",
    "h_list = []\n",
    "for i, site in enumerate(SnowMIP_sites+SnowArctic_sites):\n",
    "    h = axs[11].scatter(df_metrics_list[i].loc[('ts')].nmb[1:], marker=markers[i], label=site.name, color=colors[i])\n",
    "    h_list.append(h)\n",
    "h_mean = axs[11].scatter(df_gather.loc[('ts')].nmb[1:].apply(np.nanmean), \n",
    "                        marker=marker_mean, label=label_mean, color=color_mean, markersize=marker_mean_size)\n",
    "axs[11].scatter(df_gather_Arctic.loc[('ts')].nmb[1:].apply(np.nanmean), \n",
    "                marker=marker_mean_arc, label=label_mean_arc, color=color_mean_arc, markersize=marker_mean_arc_size)\n",
    "axs[11].format(title='Surface temperature', ylabel='Normalized bias', xrotation=xrotation, ylim=(None, None))\n",
    "\n",
    "# Soil temperature\n",
    "h_list = []\n",
    "for i, site in enumerate(SnowMIP_sites+SnowArctic_sites):\n",
    "    h = axs[12].scatter(df_metrics_list[i].loc[('tsl')].mb[1:], marker=markers[i], label=site.name, color=colors[i])\n",
    "    h_list.append(h)\n",
    "h_mean = axs[12].scatter(df_gather.loc[('tsl')].mb[1:].apply(np.nanmean), \n",
    "                        marker=marker_mean, label=label_mean, color=color_mean, markersize=marker_mean_size)\n",
    "axs[12].scatter(df_gather_Arctic.loc[('tsl')].mb[1:].apply(np.nanmean), \n",
    "                marker=marker_mean_arc, label=label_mean_arc, color=color_mean_arc, markersize=marker_mean_arc_size)\n",
    "axs[12].format(title='Soil temperature', ylabel='Mean bias [°C]', xrotation=xrotation, ylim=(None, None))\n",
    "\n",
    "h_list = []\n",
    "for i, site in enumerate(SnowMIP_sites+SnowArctic_sites):\n",
    "    h = axs[13].scatter(df_metrics_list[i].loc[('tsl')].nmb[1:], marker=markers[i], label=site.name, color=colors[i])\n",
    "    h_list.append(h)\n",
    "h_mean = axs[13].scatter(df_gather.loc[('tsl')].nmb[1:].apply(np.nanmean), \n",
    "                        marker=marker_mean, label=label_mean, color=color_mean, markersize=marker_mean_size)\n",
    "axs[13].scatter(df_gather_Arctic.loc[('tsl')].nmb[1:].apply(np.nanmean), \n",
    "                marker=marker_mean_arc, label=label_mean_arc, color=color_mean_arc, markersize=marker_mean_arc_size)\n",
    "axs[13].format(title='Soil temperature', ylabel='Normalized bias', xrotation=xrotation, ylim=(None, None))\n",
    "\n",
    "# SCD\n",
    "h_list = []\n",
    "for i, site in enumerate(SnowMIP_sites+SnowArctic_sites):\n",
    "    h = axs[14].scatter(df_metrics_list[i].loc[('SCD')].mb[1:], marker=markers[i], label=site.name, color=colors[i])\n",
    "    h_list.append(h)\n",
    "h_mean = axs[14].scatter(df_gather.loc[('SCD')].mb[1:].apply(np.nanmean), \n",
    "                        marker=marker_mean, label=label_mean, color=color_mean, markersize=marker_mean_size)\n",
    "axs[14].scatter(df_gather_Arctic.loc[('SCD')].mb[1:].apply(np.nanmean), \n",
    "                marker=marker_mean_arc, label=label_mean_arc, color=color_mean_arc, markersize=marker_mean_arc_size)\n",
    "axs[14].format(title='SCD', ylabel='Mean bias [d]', xrotation=xrotation, ylim=(None, None))\n",
    "\n",
    "h_list = []\n",
    "for i, site in enumerate(SnowMIP_sites+SnowArctic_sites):\n",
    "    h = axs[15].scatter(df_metrics_list[i].loc[('SCD')].nmb[1:], marker=markers[i], label=site.name, color=colors[i])\n",
    "    h_list.append(h)\n",
    "h_mean = axs[15].scatter(df_gather.loc[('SCD')].nmb[1:].apply(np.nanmean), \n",
    "                        marker=marker_mean, label=label_mean, color=color_mean, markersize=marker_mean_size)\n",
    "axs[15].scatter(df_gather_Arctic.loc[('SCD')].nmb[1:].apply(np.nanmean), \n",
    "                marker=marker_mean_arc, label=label_mean_arc, color=color_mean_arc, markersize=marker_mean_arc_size)\n",
    "axs[15].format(title='SCD', ylabel='Normalized bias', xrotation=xrotation, ylim=(None, None))\n",
    "\n",
    "x_min = -0.7\n",
    "x_max = 5.7\n",
    "for ax in axs:\n",
    "    # ax.format(xticklabels=['CLASS']+[exp[:-10] for exp in exps], xlim=(x_min, x_max))\n",
    "    ax.format(xticklabels=[exp[:-10] for exp in exps], xlim=(x_min, x_max))\n",
    "    ax.hlines(0, x_min, x_max, color='k', lw=1, alpha=0.3, zorder=0, ls='-')\n",
    "\n",
    "# Obs uncertainties (base on Lejeune et al. (2019) at cdp)\n",
    "axs[0].hlines([-10, 10], x_min, x_max, color='k', lw=1, alpha=0.2, zorder=0, ls='--')\n",
    "axs[2].hlines([-10, 10], x_min, x_max, color='k', lw=1, alpha=0.2, zorder=0, ls='--')\n",
    "\n",
    "axs[4].hlines([-25, 25], x_min, x_max, color='k', lw=1, alpha=0.2, zorder=0, ls='--')\n",
    "axs[6].hlines([-25, 25], x_min, x_max, color='k', lw=1, alpha=0.2, zorder=0, ls='--')\n",
    "\n",
    "axs[12].hlines([-0.4, 0.4], x_min, x_max, color='k', lw=1, alpha=0.2, zorder=0, ls='--')\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    if (i % 2) != 0:\n",
    "        ax.hlines([-1, 1], x_min, x_max, color='k', lw=1, alpha=0.2, zorder=0, ls='--')\n",
    "\n",
    "    \n",
    "fig.legend(h_list+[h_mean, h_mean_arc], loc='t', ncols=len(SnowMIP_sites)+len(SnowArctic_sites), center=True, frame=False)\n",
    "fig.format(abc='(a)', abcloc='ul')\n",
    "# fig.save('img/tn1_mb.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for var in ['snd_auto', 'snd_man', 'snw_auto', 'snw_man', 'albs', 'ts', 'tsl', 'SCD']:\n",
    "for var in ['SCD']:\n",
    "    print('### SnowMIP ###')\n",
    "    print('MB')\n",
    "    print('df_gather.loc[('+var+')].mb[1:]')\n",
    "    print(df_gather.loc[(var)].mb[1:].apply(np.nanmean))\n",
    "    \n",
    "    print('\\ndf_gather.loc[('+var+')].nmb[1:]')\n",
    "    print(df_gather.loc[(var)].nmb[1:].apply(np.nanmean))\n",
    "\n",
    "    print('\\nRMSE')\n",
    "    print('df_gather.loc[('+var+')]rmse[1:]')\n",
    "    print(df_gather.loc[(var)].rmse[1:].apply(np.nanmean))\n",
    "    \n",
    "    print('\\ndf_gather.loc[('+var+')].nrmse[1:]')\n",
    "    print(df_gather.loc[(var)].nrmse[1:].apply(np.nanmean))\n",
    "    \n",
    "    \n",
    "    print('\\n### SnowMIP + Arctic ###')\n",
    "    print('MB')\n",
    "    print('df_gather_Arctic.loc[('+var+')].mb[1:]')\n",
    "    print(df_gather_Arctic.loc[(var)].mb[1:].apply(np.nanmean))\n",
    "    \n",
    "    print('\\ndf_gather_Arctic.loc[('+var+')].nmb[1:]')\n",
    "    print(df_gather_Arctic.loc[(var)].nmb[1:].apply(np.nanmean))\n",
    "\n",
    "    print('\\nRMSE')\n",
    "    print('df_gather_Arctic.loc[('+var+')]rmse[1:]')\n",
    "    print(df_gather_Arctic.loc[(var)].rmse[1:].apply(np.nanmean))\n",
    "    \n",
    "    print('\\ndf_gather_Arctic.loc[('+var+')].nrmse[1:]')\n",
    "    print(df_gather_Arctic.loc[(var)].nrmse[1:].apply(np.nanmean))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-sc2_v0] *",
   "language": "python",
   "name": "conda-env-miniconda3-sc2_v0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
